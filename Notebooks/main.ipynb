{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "K52bKNx6dnhU",
   "metadata": {
    "id": "K52bKNx6dnhU"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xCBRbZHdS7Rz",
   "metadata": {
    "id": "xCBRbZHdS7Rz"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kdJTw02DSnK9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kdJTw02DSnK9",
    "outputId": "11ed6dc2-87a6-44f7-a162-5913ecf7aebe"
   },
   "outputs": [],
   "source": [
    "!pip install CatBoost\n",
    "!pip install country_converter\n",
    "!pip install lime -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb5bef6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdb5bef6",
    "outputId": "b7547811-8dfb-4ba7-8d67-e1ab5c2b3a8f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(style='whitegrid')\n",
    "import time\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import shap\n",
    "from matplotlib import cm\n",
    "from tqdm import tqdm\n",
    "!pip install biopython\n",
    "from Bio.Seq import Seq\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# Sklearn Module\n",
    "from sklearn.model_selection import KFold,GroupKFold,GridSearchCV,StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix,balanced_accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer,RobustScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import learning_curve,ShuffleSplit\n",
    "from sklearn.feature_selection import SelectKBest,f_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC, SMOTEN\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from catboost import CatBoostClassifier,CatBoostRegressor\n",
    "from xgboost import XGBRegressor,XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "import os,warnings;warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "M6GCwQr7xkOm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M6GCwQr7xkOm",
    "outputId": "e84b899c-2f50-4edf-de13-ab8b26be440e"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1LGnoCF392-x",
   "metadata": {
    "id": "1LGnoCF392-x"
   },
   "source": [
    "# Reading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RUNAkltE9elS",
   "metadata": {
    "id": "RUNAkltE9elS"
   },
   "outputs": [],
   "source": [
    "azm_sr_df = pd.read_csv('/content/drive/MyDrive/Dataset/azm_sr_gwas_filtered_unitigs.Rtab', sep=\"\\t\")\n",
    "cfx_sr_df = pd.read_csv('/content/drive/MyDrive/Dataset/cfx_sr_gwas_filtered_unitigs.Rtab', sep=\"\\t\")\n",
    "cip_sr_df = pd.read_csv('/content/drive/MyDrive/Dataset/cip_sr_gwas_filtered_unitigs.Rtab', sep=\"\\t\")\n",
    "metadata_df = pd.read_csv('/content/drive/MyDrive/Dataset/metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8WeXQ3Ia_Mle",
   "metadata": {
    "id": "8WeXQ3Ia_Mle"
   },
   "source": [
    "# Basic Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TUZbXm3cN5ZY",
   "metadata": {
    "id": "TUZbXm3cN5ZY"
   },
   "source": [
    "# **1. Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jKAy3nfSN99s",
   "metadata": {
    "id": "jKAy3nfSN99s"
   },
   "source": [
    "## 1.1 Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fAO1L2b4OD3v",
   "metadata": {
    "id": "fAO1L2b4OD3v"
   },
   "source": [
    "RESISTANCE OF BACTERIA\n",
    "\n",
    "  We will be focussing on a species called Neisseria gonorrhoeae, the bacteria which cause gonorrhoea.\n",
    "Gonorrhoea is the second most common sexually transmitted infection (STI) in Europe, after chlamydia.\n",
    "Rates of gonorrhoea infection are on the rise, with a 26% increase reported from 2017-2018 in the UK.\n",
    "\n",
    "  Many people who are infected (especially women) experience no symptoms, helping the disease to spread.\n",
    "If the infection is left untreated, it can lead to infertility in women, and can occasionally spread to\n",
    "other parts of the body such as your joints, heart valves, brain or spinal cord.\n",
    "Resistance of these bacteria to antibiotics is rising over time, making infections hard to treat.\n",
    "\n",
    "* In the past, patients were treated with an antibiotic called ciprofloxaxcin.\n",
    "* Doctors had to stop using this antibiotic because resistance to the drug became too common, causing treatments of infections to fail.\n",
    "* Until very recently, the recommended treatment was two drugs - ceftriaxone and azithromycin.\n",
    "* Azithromycin was removed from recommendations because of concern over rising resistance to the antibiotic.\n",
    "* In February 2018, the first ever reported case of resistance to treatment with ceftriaxone and azithromycin, as well as resistance to the last-resort treatment spectinomycin, was reported.\n",
    "* Currently in the UK, patients are only treated with ceftriaxone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DAUdHv91OUvB",
   "metadata": {
    "id": "DAUdHv91OUvB"
   },
   "source": [
    "*ANTIBIOTICS*\n",
    "\n",
    "Three antibiotics and associated unitigs are used to make a model in this problem.\n",
    "\n",
    "*Azithromycin* :\n",
    "* Azithromycin is an antibiotic used to treat various types of infections of the respiratory tract, ear, skin and eye in adults and children. It is also effective in typhoid fever and some sexually transmitted diseases like gonorrhea.\n",
    "\n",
    "*Ciprofloxacin* :\n",
    "* Ciprofloxacin is an antibiotic, used in the treatment of bacterial infections. It is also used in treating infections of the urinary tract, nose, throat, skin and soft tissues and lungs (pneumonia). It prevents the bacterial cells from dividing and repairing, thereby killing them.\n",
    "\n",
    "*Cefixime* :\n",
    "* Cefixime is an antibiotic medicine used to treat a variety of bacterial infections. It is effective in infections of the respiratory tract (eg. pneumonia), urinary tract, ear, nasal sinus, throat, and some sexually transmitted diseases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aF-BoSFPIQ5",
   "metadata": {
    "id": "3aF-BoSFPIQ5"
   },
   "source": [
    "**UNITIGS**\n",
    "\n",
    "In our dataset, we will come across features data that will convey the presence or absence of a particular nucleotide sequence in the Bacteria's DNA\n",
    "\n",
    "For this analysis, we're using unitigs, stretches of DNA (in string format) shared by a subset of the strains in our study.\n",
    "* Unitigs are an efficient but flexible way of representing DNA variation in bacteria.\n",
    "* The full dataset consists of 584,362 unitigs, which takes a long time to train models on, so for this exercise\n",
    "* We will be using a set that has been filtered for unitigs associated with resistance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eNSyu2Q-P7F_",
   "metadata": {
    "id": "eNSyu2Q-P7F_"
   },
   "source": [
    "## 1.2. Target Variables\n",
    "\n",
    "*Neisseria gonorrhoeae* is either resistant (target=1) to a particular treatment or not resistant (target=0) for a particular.\n",
    "\n",
    "AVAILABLE UNITIG DATA:\n",
    "\n",
    "* We will be choosing one of the following antibiotic cases below:\n",
    "\n",
    "  1.   Bacteria resistance to *Azithromycin; azm_sr*\n",
    "  2.   Bacteria resistance to *Ciprofloxacin; cip_sr*\n",
    "  3.   Bacteria resistance to *Cefixime; cfx_sr*\n",
    "\n",
    "UNAVAILABLE UNITIG DATA:\n",
    "\n",
    "* We don't currently have unitig data for the following antibiotics, so we can't check these cases:\n",
    "\n",
    "  1.   Bacteria resistance to *Ceftriaxone; cro_sr*\n",
    "  2.   Bacteria resistance to *Tetracycline; tet_sr*\n",
    "  3.   Bacteria reistance to *Penicillin; pen_sr*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PMNjfqdmRsx8",
   "metadata": {
    "id": "PMNjfqdmRsx8"
   },
   "source": [
    "# 2. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NO2a1V-TRxe3",
   "metadata": {
    "id": "NO2a1V-TRxe3"
   },
   "source": [
    "## 2.1. Creating Dataset\n",
    "\n",
    "**GET_UNITIGS CLASS**\n",
    "\n",
    "  *   We need to do some data wrangling & combine two data files together; `.get_case`\n",
    "  *   In this problem, a case type format is used (grouped feature matrix & target vector)\n",
    "\n",
    "The feature matrix (stored within .X) will contain:\n",
    "\n",
    "  * All collected samples from across various databses, corresponding to the bacteria's DNA (which was cut into segments of 31-mers)\n",
    "\n",
    "  * When a particular DNA segment (unitig) is present in the bacterial sample DNA, it's value is set to 1 & 0 if it's not present\n",
    "\n",
    "**MERGING RTAB & METADATA**\n",
    "\n",
    "  * Filtered Unitig data is located in .Rtab files, corresponding to the same **`sample_id`** as that of the metadata\n",
    "\n",
    "  * We need read the .Rtab files & merge the two dataframes based on the **`sample_id`** index; using .get_case()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pRIEp9hnZw8N",
   "metadata": {
    "id": "pRIEp9hnZw8N"
   },
   "outputs": [],
   "source": [
    "''' Align Metadata Target values Unitig File & Compile Feature Matrix '''\n",
    "\n",
    "class get_unitigs:\n",
    "\n",
    "    def __init__(self,verbose=True):\n",
    "        self.df = pd.read_csv('/content/drive/MyDrive/Dataset/metadata.csv', index_col=0) # metadata\n",
    "        self.meta_names = self.df.columns\n",
    "        self.target_name = None\n",
    "        self.verbose = verbose\n",
    "\n",
    "    # Get Unitig Feature matrix & Target Vector\n",
    "    def get_case(self,phenotype=None):\n",
    "\n",
    "        self.target_name = phenotype\n",
    "        _metadata = self.df\n",
    "        if(self.verbose):\n",
    "            print(f'Target Antibiotic: {self.target_name}')\n",
    "            print(f'Metadata df: {_metadata.shape}')\n",
    "\n",
    "        # remove those that don't contain target values\n",
    "        _metadata = _metadata.dropna(subset=[phenotype])\n",
    "        self.metadata = _metadata.copy()\n",
    "\n",
    "        if(self.verbose):\n",
    "            print(f'Metadata df after na() removal {_metadata.shape}')\n",
    "        _metadata = _metadata[phenotype] # choose target variable\n",
    "\n",
    "        prefix = '/content/drive/MyDrive/Dataset/'\n",
    "        suffix = '_gwas_filtered_unitigs.Rtab'\n",
    "\n",
    "        if(self.verbose):\n",
    "            print('\\nCombining Metadata & Unitigs')\n",
    "\n",
    "        # unitig feature matrix for phenotype\n",
    "        tdf = pd.read_csv(prefix + phenotype + suffix, sep=\" \",\n",
    "                          index_col=0, low_memory=False)\n",
    "        # align column data w/ metadata df (pattern_id = sample_idd)\n",
    "        tdf = tdf.T\n",
    "        # keep only common rows, ie. that have resistence measure]\n",
    "        tdf = tdf[tdf.index.isin(_metadata.index)]\n",
    "\n",
    "        train = tdf\n",
    "        target = _metadata[_metadata.index.isin(tdf.index)]\n",
    "\n",
    "        self.X = pd.concat([train,target],axis=1)\n",
    "        if(self.verbose):\n",
    "            print(f'Unitig Matrix (+target): {self.X.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8DNiSmG9dO6W",
   "metadata": {
    "id": "8DNiSmG9dO6W"
   },
   "outputs": [],
   "source": [
    "metadata_df['Year'] = metadata_df['Year'].fillna(0).astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GDiJxQa7gI7l",
   "metadata": {
    "id": "GDiJxQa7gI7l"
   },
   "source": [
    "## 2.2 Case Preview - Ciprofloxacin\n",
    "\n",
    "  We'll be looking at bacterial resistance for three different cases, let's check one case first & load the other when required..\n",
    "---\n",
    "\n",
    "**METADATA CONTENT**\n",
    "\n",
    "* Metadata is stored in .df, which contains our target variable (one of the _sr columns) for a specific Sample_ID\n",
    "\n",
    "* As we can see, we don't have all the data, some data is missing in our metadata, we'll only be dropping Nan cases for the target variable (_sr) we're concerned with.\n",
    "\n",
    "**FEATURE MATRIX**\n",
    "\n",
    "* The feature matrix is created from one of the .Rtab files, depending on which case we are testing.\n",
    "\n",
    "* Each column in the feature matrix is called a unitig (pattern_id); is treated as a feature for the specific Sample_ID, which is our index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RM9p0EDBhwWr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "id": "RM9p0EDBhwWr",
    "outputId": "2eeeac4b-da0b-4f22-f865-be68781adfc3"
   },
   "outputs": [],
   "source": [
    "# Load meta data & look at the first 5 samples\n",
    "case_cip = get_unitigs()\n",
    "\n",
    "display(case_cip.df.T.iloc[:,:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DmJBtrx4i3kj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "id": "DmJBtrx4i3kj",
    "outputId": "60a1beac-6bf4-4382-be71-925565cadca2"
   },
   "outputs": [],
   "source": [
    "case_cip.get_case(phenotype='cip_sr')\n",
    "case_cip.X.iloc[:,:2].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6hdsB8WVjpWh",
   "metadata": {
    "id": "6hdsB8WVjpWh"
   },
   "source": [
    "**TARGET VARIABLE**\n",
    "\n",
    "* The target vector, is also stored in .X, and represents the resistance property of the sample\n",
    "* The Sample_ID is either 1.0 (resistant) or 0.0 (non-resistant) to a particular antibiotic in question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gqZd0CFejuE1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gqZd0CFejuE1",
    "outputId": "e3bfa28c-295d-40df-9e19-190bb5bb8e06"
   },
   "outputs": [],
   "source": [
    "target = case_cip.X[case_cip.target_name]\n",
    "print(target[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QcRVPajhkGWu",
   "metadata": {
    "id": "QcRVPajhkGWu"
   },
   "source": [
    "## 2.3. Target Variable Distribution\n",
    "\n",
    "**TARGET DISTRIBUTIONS & UNITIG COUNT**\n",
    "\n",
    "* It's useful to look at the class distributions for all three cases we'll be making models for.\n",
    "* As we can see below, the unitig distributions are quite different as well, so our feature matrix will vary significantly for each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wP0OLCSqkY6R",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wP0OLCSqkY6R",
    "outputId": "2773fd2f-d212-4267-b45d-b22531d51d66"
   },
   "outputs": [],
   "source": [
    "''' Ciprofloxacin '''\n",
    "\n",
    "case = get_unitigs()\n",
    "case.get_case('cip_sr')\n",
    "print(case.X[case.target_name].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2JmNBZ3ckesV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2JmNBZ3ckesV",
    "outputId": "ee8dac82-bd59-4a1c-c2df-d022c23a7145"
   },
   "outputs": [],
   "source": [
    "''' Azithromycin '''\n",
    "\n",
    "case = get_unitigs()\n",
    "case.get_case('azm_sr')\n",
    "print(case.X[case.target_name].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-Um3Ng07kifE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Um3Ng07kifE",
    "outputId": "860099b9-413f-4b45-9c08-2548f0396ab1"
   },
   "outputs": [],
   "source": [
    "''' Cefixime '''\n",
    "\n",
    "case = get_unitigs()\n",
    "case.get_case('cfx_sr')\n",
    "print(case.X[case.target_name].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mBRZfY_Ll9Wc",
   "metadata": {
    "id": "mBRZfY_Ll9Wc"
   },
   "source": [
    "# 3.Feature Matrix Modification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pq-cFxhLmCh5",
   "metadata": {
    "id": "pq-cFxhLmCh5"
   },
   "source": [
    "## 3.1.Creating Case Data\n",
    "\n",
    "* In Section 2.3, we saw that for some antibiotics, there are very few resistant samples present , mainly Cefixime\n",
    "* This results in a very tricky situation if we want to use cross validation, we may not even have enough samples for the model to learn anything meaningful\n",
    "* Creating models Azithromycin & Ciprofloxacin should not have this issue, as we have sufficient number of samples, even if an imbalance is present\n",
    "\n",
    "We can try two approaches:\n",
    "\n",
    "* Downsample the dominant class (not resistant) `.split_case`\n",
    "* Utilise SMOTE based upsampling strategy `smote`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rtZSjqtpq0wG",
   "metadata": {
    "id": "rtZSjqtpq0wG"
   },
   "outputs": [],
   "source": [
    "''' Feature Matrix Upsampling Modification (+Target) '''\n",
    "# Model based approach to upsample minor class in target variable\n",
    "\n",
    "class mod_unitigs():\n",
    "\n",
    "    def __init__(self,unitigs):\n",
    "        self.X = unitigs.X # input data class\n",
    "        self.target_name = unitigs.target_name\n",
    "        self.verbose = True\n",
    "\n",
    "    ''' Downsampling Class 0 using .sample & recompile '''\n",
    "    # If there's too much of the dominant class, just downsample\n",
    "\n",
    "    def split_case(self,frac_id=0.5):\n",
    "\n",
    "        X = self.train\n",
    "        y = pd.Series(self.target,name=self.target_name)\n",
    "        XX = pd.concat([X,y],axis=1)\n",
    "\n",
    "        lst_temp = dict(tuple(XX.groupby(self.target_name))) # divide classes\n",
    "        ratio = lst_temp[0].shape[0]/lst_temp[1].shape[0] # get class ratio\n",
    "\n",
    "        # Sample approach for downsizing majority class\n",
    "        X_red = lst_temp[0].sample(frac=frac_id)\n",
    "        X_all = pd.concat([X_red,lst_temp[1]],axis=0)\n",
    "\n",
    "        if(self.verbose):\n",
    "            print(f'Class 0 : {lst_temp[0].shape}')\n",
    "            print(f'Class 1 : {lst_temp[1].shape}')\n",
    "            print(f'Class Ratio: {round(ratio,4)}')\n",
    "            print(f'Reduced Training Matrix: {X_all.shape}')\n",
    "\n",
    "        # Redefine .train, .target\n",
    "        self.target = X_all[self.target_name].copy()\n",
    "        X_all.drop(self.target_name, inplace=True, axis=1)\n",
    "        self.train = X_all\n",
    "\n",
    "    ''' SMOTE UPSAMPLING '''\n",
    "    # For unbalanced problems, synthetically/model new data\n",
    "\n",
    "    def smote(self,smote_id = 'smotenc',\n",
    "                   smote_strat=0.5,\n",
    "                   k_neighbours=5):\n",
    "\n",
    "        self.smote_id = smote_id\n",
    "        self.smote_strat = smote_strat\n",
    "        self.smote_nbr = k_neighbours\n",
    "\n",
    "        y = self.X[self.target_name].copy()\n",
    "        X = self.X.drop([self.target_name],axis=1).copy()\n",
    "\n",
    "        # smote for contin, smotenc for category\n",
    "        if(self.smote_id == 'smote'):\n",
    "            model_id = SMOTE(sampling_strategy=self.smote_strat,\n",
    "                             k_neighbors=self.smote_nbr)\n",
    "        elif(self.smote_id == 'smotenc'):\n",
    "            model_id = SMOTENC(sampling_strategy=self.smote_strat,\n",
    "                               k_neighbors=self.smote_nbr,\n",
    "                               categorical_features=[0,1])\n",
    "\n",
    "        X_mod, y_mod = model_id.fit_resample(X,y)\n",
    "        self.X = pd.concat([X_mod,y_mod],axis=1)\n",
    "\n",
    "        if(self.verbose):\n",
    "            print(f'\\nSMOTE Upsampling: {self.X.shape}')\n",
    "            print(f'Target Value Counts: \\n{pd.Series(y_mod).value_counts()}')\n",
    "        self.X = pd.concat([X_mod,y_mod],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tgFZDNa148v_",
   "metadata": {
    "id": "tgFZDNa148v_"
   },
   "source": [
    "# 4.Explotary Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FSxbLOlW5Vcw",
   "metadata": {
    "id": "FSxbLOlW5Vcw"
   },
   "source": [
    "## 4.1. Parallel Categories\n",
    "\n",
    "**EXPLORING THE METADATA**\n",
    "\n",
    "* Aside from the unitig data, the Metadata Dataset contains some interesting info about each Sample_ID as well.\n",
    "* Having sorted by the X_mic column, *log2_X_mic* has the same ordering as X_mic & antibiotic column name, so it was not included to reduce clutter in the figures.\n",
    "* Beta.lactamase relation to antibiotic resistance doesn't seem to exhibit any particular patterns, other than Penicillin, for which the R (resistant) type almost exclsively indicates that the antibiotic will not be effective.\n",
    "* Most bacteria *Sample_ID* are also shown to be of S (sensitive) type.\n",
    "* If we highlight the uttermost right column, _sr, we can also note that resistance of these bacteria to antibiotics tends to be rising over time.\n",
    "* These figures clearly indicate that *cefixime* by far is the most effective treatment out of the tree antibiotics.\n",
    "* *Ciprofloxacin* on the otherhand has not been very effective treatment against the bacteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DeiApUOn6qqI",
   "metadata": {
    "id": "DeiApUOn6qqI"
   },
   "outputs": [],
   "source": [
    "lst_azm = ['Year','Country','Continent','Beta.lactamase','azm_mic','Azithromycin','azm_sr']\n",
    "lst_cip = ['Year','Country','Continent','Beta.lactamase','cip_mic','Ciprofloxacin','cip_sr']\n",
    "lst_cfx = ['Year','Country','Continent','Beta.lactamase','cfx_mic','Cefixime','cfx_sr']\n",
    "lst_antibio = [lst_azm,lst_cip,lst_cfx]\n",
    "\n",
    "# Plot Parallel Categories Plot\n",
    "def plot_pp(lst,colour='ghostwhite'):\n",
    "    tdf = get_unitigs().df[lst]\n",
    "    tdf.dropna(inplace=True)\n",
    "    tdf.sort_values(by=lst[-3],inplace=True,ascending=False)\n",
    "    tdf['Year'] = tdf['Year'].astype(str)\n",
    "    fig = px.parallel_categories(tdf)\n",
    "    fig.update_traces(patch={\"line\": {\"color\":colour,'shape':'hspline'}})\n",
    "    fig.update_layout(title=f'Bacteria Resistance to {lst[-2]}')\n",
    "    fig.update_layout(margin=dict(t=60,b=10),height=400)\n",
    "    fig.show()\n",
    "\n",
    "def plot_geomean(lst):\n",
    "\n",
    "    global country_map\n",
    "\n",
    "    tdf = get_unitigs().df[lst]\n",
    "    tdf.dropna(inplace=True)\n",
    "    tdf.sort_values(by=lst[-3],inplace=True,ascending=False)\n",
    "    # tdf['Year'] = tdf['Year'].astype(str) # Exclude 'Year' from mean calculation\n",
    "\n",
    "    tdf['Country'] = tdf['Country'].map(country_map)\n",
    "    # Select only numeric columns for mean calculation\n",
    "    numeric_cols = tdf.select_dtypes(include=np.number).columns.tolist()\n",
    "    tdf2 = tdf.groupby(['Country'])[numeric_cols].mean()\n",
    "\n",
    "    fig = go.Figure(data=go.Choropleth(\n",
    "        locations = tdf2.index,\n",
    "        z = tdf2[lst[-1]],\n",
    "        colorscale = 'magenta',\n",
    "        autocolorscale=False,\n",
    "        reversescale=False,\n",
    "        marker_line_color='black',\n",
    "        marker_line_width=0.5,\n",
    "        colorbar_title = f'{lst[-1]}'))\n",
    "\n",
    "    fig.update_layout(title=f'Bacteria Resistance to {lst[-2]}',\n",
    "                      geo=dict(showframe=False,showcoastlines=False,\n",
    "                               projection_type='equirectangular'))\n",
    "    fig.update_layout(margin=dict(t=60,b=10),height=400)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-9c1n_QJ6uCX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-9c1n_QJ6uCX",
    "outputId": "1445358d-f530-4de0-c73d-03c34e4784a5"
   },
   "outputs": [],
   "source": [
    "for i in lst_antibio:\n",
    "    plot_pp(i,'mistyrose')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9nJ8b5Zp7J95",
   "metadata": {
    "id": "9nJ8b5Zp7J95"
   },
   "source": [
    "## 4.2. Country Based Bacteria Resistance\n",
    "\n",
    "**LEAST EFFECTIVE TREATMENT LOCATIONS**\n",
    "\n",
    "The result sample pool may not be very balanced to make specific conclusions, but resistance to specific anibiotics has some geographic variation.\n",
    "\n",
    "* For Azithromycin, samples from the US, Sweden & China are shown to be only countries with unsuccesful treatment cases.\n",
    "* Globally, Ciprofloxacin has become an innefective treatment. Chile, Finland, Vietnam, China are amonst the least effective locations.\n",
    "* Aside from France, Cefixime has been the most effective treatment globally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o7q8DT4-7atz",
   "metadata": {
    "id": "o7q8DT4-7atz"
   },
   "outputs": [],
   "source": [
    "import country_converter as coco\n",
    "\n",
    "lst_azm = ['Year','Country','Continent','Beta.lactamase','azm_mic','Azithromycin','azm_sr']\n",
    "lst_cip = ['Year','Country','Continent','Beta.lactamase','cip_mic','Ciprofloxacin','cip_sr']\n",
    "lst_cfx = ['Year','Country','Continent','Beta.lactamase','cfx_mic','Cefixime','cfx_sr']\n",
    "lst_antibio = [lst_azm,lst_cip,lst_cfx]\n",
    "\n",
    "#tdf['Country'] = coco.convert(names=tdf['Country'].astype(str), to='ISO3', not_found=None)\n",
    "\n",
    "def plot_geomean(lst):\n",
    "\n",
    "    #global country_map\n",
    "\n",
    "    tdf = get_unitigs().df[lst]\n",
    "    tdf.dropna(inplace=True)\n",
    "    tdf.sort_values(by=lst[-3],inplace=True,ascending=False)\n",
    "    tdf['Year'] = tdf['Year'].astype(str)\n",
    "\n",
    "    tdf['Country'] = coco.convert(names=tdf['Country'].replace(\n",
    "        {'Brasil':'Brazil',\n",
    "         'Scotland':'United Kingdom',\n",
    "         'Caribbean':'Caribbean Netherlands'}).astype(str), to='ISO3', not_found=None)\n",
    "\n",
    "    tdf2 = tdf.groupby(['Country']).mean(numeric_only=True)\n",
    "\n",
    "    fig = go.Figure(data=go.Choropleth(\n",
    "        locations = tdf2.index,\n",
    "        z = tdf2[lst[-1]],\n",
    "        colorscale = 'magenta',\n",
    "        autocolorscale=False,\n",
    "        reversescale=False,\n",
    "        marker_line_color='black',\n",
    "        marker_line_width=0.5,\n",
    "        colorbar_title = f'{lst[-1]}'))\n",
    "\n",
    "    fig.update_layout(title=f'Bacteria Resistance to {lst[-2]}',\n",
    "                      geo=dict(showframe=False,showcoastlines=False,\n",
    "                               projection_type='equirectangular'))\n",
    "    fig.update_layout(margin=dict(t=60,b=10),height=400)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YN7s6i7T8flh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YN7s6i7T8flh",
    "outputId": "090ec75b-0156-4ca5-f0b1-636ed2303359"
   },
   "outputs": [],
   "source": [
    "# Plot Choropleth Map\n",
    "for i in lst_antibio:\n",
    "    plot_geomean(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DPKF340S9CWV",
   "metadata": {
    "id": "DPKF340S9CWV"
   },
   "source": [
    "## 4.3. MIC Values of All Samples\n",
    "\n",
    "* *MIC* : a measure of the *concentration of antibiotic* bacteria can tolerate before it impairs their growth.\n",
    "* We can definitely note a correlation to _mic features for antibiotic resistance in this graph alone:\n",
    "  * Only small quantities of Cefixime are required to impair bacterial growth.\n",
    "  * Compared to Azithromycin & Ciprofloxacin, which concentrate higher values of _mic as well\n",
    "  * Hinting that it's less effective or that the bacteria is tending to become more resistant to the antibiotic & larger quantities are required to affect its function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1zeFjrkA9vLZ",
   "metadata": {
    "id": "1zeFjrkA9vLZ"
   },
   "outputs": [],
   "source": [
    "def get_mic():\n",
    "\n",
    "    lst_cases = ['azm_mic','cip_mic','cfx_mic']\n",
    "    rtabs = ['azm_sr','cip_sr','cfx_sr']\n",
    "    lst_temp = []\n",
    "\n",
    "    ii=-1\n",
    "    for case in lst_cases:\n",
    "\n",
    "        ii+=1\n",
    "        case_id = get_unitigs(verbose=False)\n",
    "        case_id.get_case(rtabs[ii])\n",
    "\n",
    "        X_all = pd.concat([case_id.X,case_id.metadata],axis=1)\n",
    "\n",
    "        new_df = X_all[case].value_counts().rename_axis(case).reset_index(name='counts')\n",
    "        new_df = new_df.rename(columns={new_df.columns[0]: 'mic'})\n",
    "        new_df['case'] = case\n",
    "        lst_temp.append(new_df)\n",
    "\n",
    "    X_counts = pd.concat([lst_temp[0],lst_temp[1],lst_temp[2]],axis=0)\n",
    "    X_counts.sort_values(by='mic',inplace=True,ascending=True)\n",
    "    X_counts['mic'] = X_counts['mic'].astype(str)\n",
    "\n",
    "    fig = px.bar(X_counts, x='mic',y='counts',color='case')\n",
    "    fig.update_layout(template='plotly_white',height=300)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JCS---z69xWc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "JCS---z69xWc",
    "outputId": "71f903f4-529a-46c2-9d97-ed31cb17f67e"
   },
   "outputs": [],
   "source": [
    "get_mic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3AMW7RYl92MR",
   "metadata": {
    "id": "3AMW7RYl92MR"
   },
   "source": [
    "## 4.4 UNITIG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VPd56-89-Zk7",
   "metadata": {
    "id": "VPd56-89-Zk7"
   },
   "source": [
    "**UNIQUE VALUES OF ALL UNITIGS**\n",
    "\n",
    "All columns in the feature matrix .X, used for training contains only values for *present (1)* or not *present (0)* for each Sample_ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gdncwza7-HGx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gdncwza7-HGx",
    "outputId": "e336401d-d10c-4a1a-d7c3-9cff5c865f97"
   },
   "outputs": [],
   "source": [
    "column_values = case.X[case.target_name].values.ravel()\n",
    "print(pd.unique(column_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ar_CeenU-Szv",
   "metadata": {
    "id": "ar_CeenU-Szv"
   },
   "source": [
    "**GROUPED UNITIGS**\n",
    "\n",
    "Some columns also contain multiple *unitigs* which we can note below as well, perhaps indicating that all grouped unitigs must be present in a given Sample_ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pzvf0oNd-ljq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pzvf0oNd-ljq",
    "outputId": "43793f89-04d1-4c43-9089-27042f15be4a"
   },
   "outputs": [],
   "source": [
    "case_unitigs = case.X.columns.tolist()\n",
    "\n",
    "ii=-1\n",
    "for i in case_unitigs:\n",
    "    if(',' in i):\n",
    "        ii+=1;print(f'{ii} | {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MLdpIizz_GQP",
   "metadata": {
    "id": "MLdpIizz_GQP"
   },
   "source": [
    "This output shows that some columns represent combined groups of multiple unitigs, and a value of 1 means that all those unitigs are present together in the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PP2PkvraAlkY",
   "metadata": {
    "id": "PP2PkvraAlkY"
   },
   "source": [
    "**WORKING WITH SEQUENCES**\n",
    "\n",
    "* Unitigs are composed of **nucleotides**, which means we can use the SQ() class.\n",
    "* Alternatively, we can use the **BioPython** module as well, storing the sequence data in Seq instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AmKOD8AoAy2t",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AmKOD8AoAy2t",
    "outputId": "df197358-d45a-49d5-a189-1180879dee35"
   },
   "outputs": [],
   "source": [
    "# Using SQ() Class we can define sequences\n",
    "\n",
    "lst_SQ = []\n",
    "for unitig in case_unitigs:\n",
    "    pass\n",
    "# lst_SQ.append(SQ(unitig,'DNA'))\n",
    "\n",
    "# print(type(lst_SQ[4]))\n",
    "\n",
    "# Using BioPython we can define sequences\n",
    "\n",
    "lst_bSQ = []\n",
    "for unitig in case_unitigs:\n",
    "    lst_bSQ.append(Seq(unitig))\n",
    "\n",
    "print(type(lst_bSQ[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7rTv6gmRMmD2",
   "metadata": {
    "id": "7rTv6gmRMmD2"
   },
   "source": [
    "##4.5 Temporal Trends in Antibiotic Resistance\n",
    "\n",
    "This section explores the temporal patterns of resistance to three antibiotics: **Azithromycin (AZM)**, **Ciprofloxacin (CIP)**, and **Cefixime (CFX)**. By analyzing resistance rates over time, we aim to assess whether resistance to these antibiotics has increased or decreased across the years.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aUZT7Oe4NY3Z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "id": "aUZT7Oe4NY3Z",
    "outputId": "1eb7b0ff-30b9-4581-aa49-35271ba64c4d"
   },
   "outputs": [],
   "source": [
    "# Filter out invalid or out-of-range years\n",
    "metadata_df['Year'] = metadata_df['Year'].astype('Int64')\n",
    "valid_years_df = metadata_df[(metadata_df['Year'] >= 2000) & (metadata_df['Year'] <= 2025)]\n",
    "\n",
    "# Group by year and compute resistance percentages\n",
    "antibiotics = ['azm_sr', 'cip_sr', 'cfx_sr']\n",
    "resistance_by_year = valid_years_df.groupby('Year')[antibiotics].mean() * 100\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "for abx in antibiotics:\n",
    "    plt.plot(resistance_by_year.index, resistance_by_year[abx], marker='o', label=abx.upper())\n",
    "\n",
    "plt.title('Antibiotic Resistance Trends Over the Years (AZM, CIP, CFX)', fontsize=14)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Resistance Rate (%)')\n",
    "plt.legend(title='Antibiotic')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6pCoxFAHQRWL",
   "metadata": {
    "id": "6pCoxFAHQRWL"
   },
   "source": [
    "##4.6 Multidrug Resistance (MDR) Profile Distribution\n",
    "\n",
    "This section investigates the distribution of multidrug resistance (MDR) among the samples based on their resistance to three antibiotics: **Azithromycin (AZM)**, **Ciprofloxacin (CIP)**, and **Cefixime (CFX)**.\n",
    "\n",
    "A sample is considered **MDR** if it is resistant to **at least two** of these antibiotics. We compute how many samples are resistant to 0, 1, 2, or all 3 of the selected antibiotics and visualize the distribution using a bar plot. This provides an overview of the prevalence of multidrug-resistant profiles in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9S66MsMhQcYd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "9S66MsMhQcYd",
    "outputId": "8b7e4008-f9d4-4cc8-a7bf-22e1e8df34be"
   },
   "outputs": [],
   "source": [
    "# Calculate number of resistances per sample across AZM, CIP, CFX\n",
    "resistance_cols = ['azm_sr', 'cip_sr', 'cfx_sr']\n",
    "metadata_df['resistance_count'] = metadata_df[resistance_cols].sum(axis=1)\n",
    "\n",
    "# Count how many samples are resistant to 0, 1, 2, or 3 antibiotics\n",
    "resistance_distribution = metadata_df['resistance_count'].value_counts().sort_index()\n",
    "\n",
    "# Plot distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=resistance_distribution.index, y=resistance_distribution.values, palette='Set2')\n",
    "plt.title('Distribution of Resistance Count (AZM, CIP, CFX)', fontsize=14)\n",
    "plt.xlabel('Number of Resistant Antibiotics')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xticks([0, 1, 2, 3])\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jadsyhkhcQ0J",
   "metadata": {
    "id": "jadsyhkhcQ0J"
   },
   "source": [
    "##4.7 MIC Distributions and Breakpoints (log2 Transformed)\n",
    "\n",
    "This section analyzes the distribution of log2-transformed Minimum Inhibitory Concentration (MIC) values for three antibiotics: **Azithromycin (AZM)**, **Ciprofloxacin (CIP)**, and **Cefixime (CFX)**.\n",
    "\n",
    "MIC distributions provide insights into the population-level susceptibility or resistance tendencies, and when compared against established **clinical breakpoints**, they help distinguish between susceptible and resistant isolates.\n",
    "\n",
    "Histograms are plotted for each antibiotic’s log2 MIC values, with vertical lines marking the corresponding clinical resistance breakpoints based on EUCAST or CLSI guidelines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iw62zTywcUjw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "iw62zTywcUjw",
    "outputId": "9f9d96c6-a70b-4c40-f1c8-12923d6f4daa"
   },
   "outputs": [],
   "source": [
    "# Define antibiotics and their log2 MIC columns and breakpoints\n",
    "mic_info = {\n",
    "    'AZM': {'col': 'log2_azm_mic', 'breakpoint': 3},   # example: 2^3 = 8 µg/mL\n",
    "    'CIP': {'col': 'log2_cip_mic', 'breakpoint': -1},  # example: 2^-1 = 0.5 µg/mL\n",
    "    'CFX': {'col': 'log2_cfx_mic', 'breakpoint': -1}   # example: 2^-1 = 0.5 µg/mL\n",
    "}\n",
    "\n",
    "# Plot MIC histograms\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "for i, (abx, info) in enumerate(mic_info.items(), 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    sns.histplot(metadata_df[info['col']].dropna(), bins=20, kde=False, color='steelblue')\n",
    "    plt.axvline(info['breakpoint'], color='red', linestyle='--', label='Resistance Breakpoint')\n",
    "    plt.title(f'{abx} - log2 MIC Distribution')\n",
    "    plt.xlabel('log2(MIC)')\n",
    "    plt.ylabel('Sample Count')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qgEuFrebeg8K",
   "metadata": {
    "id": "qgEuFrebeg8K"
   },
   "source": [
    "##4.8 Correlation Between Antibiotics (log2 MIC Values)\n",
    "\n",
    "In this section, we explore the pairwise correlations between the log2-transformed MIC values of Azithromycin (AZM), Ciprofloxacin (CIP), and Cefixime (CFX).\n",
    "\n",
    "By computing both the correlation matrix and scatterplots, we aim to visually and statistically assess whether susceptibility to one antibiotic is associated with susceptibility to another. This may help identify shared resistance patterns or independent mechanisms of resistance across the antibiotics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Qel7E79cerAM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "id": "Qel7E79cerAM",
    "outputId": "39ba96db-cfdb-4bb9-a2d7-9e114489e039"
   },
   "outputs": [],
   "source": [
    "# Select log2 MIC columns\n",
    "mic_cols = ['log2_azm_mic', 'log2_cip_mic', 'log2_cfx_mic']\n",
    "mic_df = metadata_df[mic_cols].dropna()\n",
    "\n",
    "# Compute correlation matrix\n",
    "correlation_matrix = mic_df.corr(method='pearson')\n",
    "\n",
    "# Display correlation heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix of log2 MIC Values (AZM, CIP, CFX)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fNr8DXYZk1Gu",
   "metadata": {
    "id": "fNr8DXYZk1Gu"
   },
   "source": [
    "##4.9 Antibiotic Resistance Trends by Country (Top 5 Sample Contributors)\n",
    "\n",
    "To investigate potential geographic patterns, we first identify the top 5 countries that contributed the highest number of samples.\n",
    "\n",
    "We then examine how resistance rates to azithromycin, ciprofloxacin, and cefixime have changed over time within those countries. This analysis may reveal differing national resistance trends and local epidemiological dynamics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3wIpxw_p-ni",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "b3wIpxw_p-ni",
    "outputId": "c11fc5c5-bd24-4415-ca4f-19362a450bfc"
   },
   "outputs": [],
   "source": [
    "top_countries = (\n",
    "    metadata_df['Country']\n",
    "    .value_counts()\n",
    "    .head(5)\n",
    "    .index\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "filtered_df = metadata_df[metadata_df['Country'].isin(top_countries)]\n",
    "\n",
    "antibiotics = {\n",
    "    'azm_sr': 'Azithromycin',\n",
    "    'cip_sr': 'Ciprofloxacin',\n",
    "    'cfx_sr': 'Cefixime'\n",
    "}\n",
    "\n",
    "for abx_col, abx_name in antibiotics.items():\n",
    "    trend_df = (\n",
    "      filtered_df[filtered_df['Year'].between(2000, 2030)]  # Yıl filtresi eklendi\n",
    "        .groupby(['Country', 'Year'])[abx_col]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .dropna()\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.lineplot(data=trend_df, x='Year', y=abx_col, hue='Country', marker='o')\n",
    "    plt.title(f'Resistance Rate over Time in Top 5 Countries - {abx_name}')\n",
    "    plt.ylabel('Resistance Rate')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "niTxAohQOYXR",
   "metadata": {
    "id": "niTxAohQOYXR"
   },
   "source": [
    "##4.10 Beta-lactamase Gene Presence Over Time\n",
    "\n",
    "The presence of the Beta-lactamase gene is a critical indicator of bacterial resistance to beta-lactam antibiotics.\n",
    "This gene can inactivate a wide range of antibiotics, making treatment difficult. In this section, we visualize the\n",
    "temporal trend of Beta-lactamase gene detection across years to observe any increase or fluctuation over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qxTYQoXhOeDl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "qxTYQoXhOeDl",
    "outputId": "bd8fab39-bf91-421f-dc14-51950f954be4"
   },
   "outputs": [],
   "source": [
    "# Clean and standardize 'Beta.lactamase' values\n",
    "metadata_df['Beta_lactamase_status'] = metadata_df['Beta.lactamase'].apply(\n",
    "    lambda x: 'Present' if str(x).strip().upper() in ['1', '2', 'R', 'S'] else 'Absent'\n",
    ")\n",
    "\n",
    "# Group by Year and Status\n",
    "beta_clean_df = (\n",
    "    metadata_df[metadata_df['Year'].between(1998, 2030)]\n",
    "    .groupby(['Year', 'Beta_lactamase_status'])['Sample_ID']\n",
    "    .count()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Pivot table for plotting\n",
    "beta_clean_pivot = beta_clean_df.pivot(index='Year', columns='Beta_lactamase_status', values='Sample_ID').fillna(0)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "beta_clean_pivot.plot(kind='bar', stacked=True, colormap='Paired', figsize=(12, 5))\n",
    "plt.title('Yearly Trend of Beta-lactamase Presence (Cleaned)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.legend(title='Beta-lactamase Status')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mOnET-MRPL2d",
   "metadata": {
    "id": "mOnET-MRPL2d"
   },
   "source": [
    "## 4.11 Sample Collection Intensity by Continent and Year\n",
    "\n",
    "To better understand the structure of the dataset and assess potential sampling bias, we visualized the number of samples collected per continent over time.\n",
    "\n",
    "This heatmap reveals the temporal and geographic distribution of data collection. It helps identify periods of increased surveillance, under-represented regions, or potential shifts in sampling policies that may affect the interpretation of resistance trends.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BVYuIE90PQ4q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "id": "BVYuIE90PQ4q",
    "outputId": "a8765cb7-e029-4269-fb10-9394a7e1449f"
   },
   "outputs": [],
   "source": [
    "# Group by Continent and Year\n",
    "collection_df = (\n",
    "    metadata_df[metadata_df['Year'].between(1990, 2030)]\n",
    "    .groupby(['Continent', 'Year'])['Sample_ID']\n",
    "    .count()\n",
    "    .reset_index()\n",
    "    .rename(columns={'Sample_ID': 'Sample_Count'})\n",
    ")\n",
    "\n",
    "# Pivot for heatmap\n",
    "heatmap_data = collection_df.pivot(index='Continent', columns='Year', values='Sample_Count').fillna(0)\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.heatmap(heatmap_data, annot=True, fmt=\".0f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Sample Count'})\n",
    "plt.title('Sample Collection Intensity by Continent and Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Continent')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h7S5GC8vQF1e",
   "metadata": {
    "id": "h7S5GC8vQF1e"
   },
   "source": [
    "## 4.12 Beta-lactamase Presence vs Resistance Status Across Antibiotics\n",
    "\n",
    "To explore the potential association between beta-lactamase enzyme presence and antibiotic resistance, we examined resistance rates (AZM, CIP, CFX) across samples grouped by their beta-lactamase status.\n",
    "\n",
    "This comparison may reveal whether the production of beta-lactamase — an enzyme capable of breaking down certain antibiotics — correlates with higher resistance rates, even for non-beta-lactam drugs. Although none of the three target antibiotics are beta-lactams, this analysis may indicate co-selection or linked resistance mechanisms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dAjt1P1lQcn0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "dAjt1P1lQcn0",
    "outputId": "714f4bfd-953d-4e3c-a3f3-cf7119ec7271"
   },
   "outputs": [],
   "source": [
    "# Clean Beta-lactamase values again for consistency\n",
    "metadata_df['Beta_lactamase_status'] = metadata_df['Beta.lactamase'].apply(\n",
    "    lambda x: 'Present' if str(x).strip().upper() in ['1', '2', 'R', 'S'] else 'Absent'\n",
    ")\n",
    "\n",
    "# Calculate resistance rate per group\n",
    "resistance_summary = metadata_df.groupby('Beta_lactamase_status')[['azm_sr', 'cip_sr', 'cfx_sr']].mean().reset_index()\n",
    "\n",
    "# Reshape for plotting\n",
    "resistance_melted = resistance_summary.melt(id_vars='Beta_lactamase_status',\n",
    "                                             var_name='Antibiotic',\n",
    "                                             value_name='Resistance Rate')\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=resistance_melted, x='Antibiotic', y='Resistance Rate', hue='Beta_lactamase_status')\n",
    "plt.title('Antibiotic Resistance by Beta-lactamase Status')\n",
    "plt.ylabel('Resistance Rate (%)')\n",
    "plt.xlabel('Antibiotic')\n",
    "plt.legend(title='Beta-lactamase')\n",
    "plt.ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6iZ5xteVGcJd",
   "metadata": {
    "id": "6iZ5xteVGcJd"
   },
   "source": [
    "# 5.Creating Resistance Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n83EZ-tQGfYV",
   "metadata": {
    "id": "n83EZ-tQGfYV"
   },
   "source": [
    "## 5.1 List of Tuple Models\n",
    "\n",
    "**ADDING MODELS TO LIST models**\n",
    "\n",
    "* We define a list of tuples from which we can access the case (Model Name, Model Instance & CV Parameters) & use them in the evaluation class.\n",
    "* A dictionary contaning CV Parameters (third term) is only required when calling `.gscv()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uO2cNf5QH2bR",
   "metadata": {
    "id": "uO2cNf5QH2bR"
   },
   "outputs": [],
   "source": [
    "# models use in kfold\n",
    "models = []\n",
    "models.append(\n",
    "    ('LDA', LinearDiscriminantAnalysis()))\n",
    "\n",
    "# models use in gscv\n",
    "cv_lda = {'solver':\n",
    "              ['svd', 'lsqr', 'eigen']}\n",
    "\n",
    "models = []\n",
    "models.append(\n",
    "    ('LDA', LinearDiscriminantAnalysis(),cv_lda))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4BN4y3fjH4i5",
   "metadata": {
    "id": "4BN4y3fjH4i5"
   },
   "source": [
    "## 5.2 Model Evaluation Class\n",
    "\n",
    "**CLASS INSTANCE INPUTS**\n",
    "\n",
    "* We'll define a class, class_eval that will be used for evaluation purposes.\n",
    "* We can instantiate class_eval having defined:\n",
    "  * *Data/Case Class* containing feature & target vector (get_unitifs or mod_unitigs)\n",
    "  * *List of models* (containing tuples)\n",
    "  * *nfold* (number of kfold splits)\n",
    "  * *gsfold* (number of gridsearch folds)\n",
    "\n",
    "**EVALUATION OPTIONS**\n",
    "\n",
    "Using the self.models defined during instantiation:\n",
    "\n",
    "  * `.cv(type_id)` : kfold Cross validation is done with the selected model(s) with the set hyperparameters.\n",
    "  * `.gscv(type_id)` : kfold cross validation but with Grid Search, best mean balanced_accuracy score hyperparamers used for fitting on whole kfold subset.\n",
    "\n",
    "Both functions require kfold type input type_id: Standard (kfold) / Stratified (skfold)\n",
    "\n",
    "**gscv**\n",
    "\n",
    "For all input models, defined with grid-search hyperparameters (third term):\n",
    "\n",
    "  We split the dataset into nfold groups containing both training & test data\n",
    "  For each train segment data, we use GridSearchCV to find the best scoring model using the provided parameter dictionary.\n",
    "  Using the best scoring model on the training set, we evaluate both training & test scoring using the evaluation metric.\n",
    "  For outputs, we recall the best scoring hyperparameters & confusion matrix for each fold.\n",
    "\n",
    "**cv**\n",
    "\n",
    "For all input models:\n",
    "\n",
    "  * We split the dataset into nfold groups containing both training & test data\n",
    "  * For each nfold, we have a training & test set. On this data we evaluate our model w/ predefined hyperparameters.\n",
    "  * Results for each fold are stored in .dic_tr & .dic_te which can be visualised by calling .fold_plot()\n",
    "\n",
    "**EVALUATION METRIC**\n",
    "\n",
    "* As we saw in Section 2&3, the *target variable* in our binary classification problem can be very one sided\n",
    "* Let's use *balanced_accuracy*, which is suitable for imbalanced class problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QLWYi43uQeuj",
   "metadata": {
    "id": "QLWYi43uQeuj"
   },
   "outputs": [],
   "source": [
    "class class_eval():\n",
    "\n",
    "    def __init__(self,data=None,models=None,nfold = 4,\n",
    "                 gsfold=3, verbose=True,\n",
    "                 shuffle_id=False,random_state=22):\n",
    "\n",
    "        self.shuffle = shuffle_id\n",
    "\n",
    "        if(self.shuffle is False):\n",
    "            self.rs = None\n",
    "        else:\n",
    "            self.rs = random_state # random state\n",
    "\n",
    "        if(data is not None):\n",
    "            X_all = data.X\n",
    "            self.y = data.X[data.target_name].copy()\n",
    "            self.X = data.X.drop([data.target_name],axis=1).copy()\n",
    "        else:\n",
    "            print('input case data')\n",
    "\n",
    "        self.models = models # Tuple /w (name,model)\n",
    "        self.nfold = nfold       # number of cross validation folds\n",
    "        self.gsfold = gsfold    # number of grid search folds in every fold\n",
    "        self.target_name = data.target_name  # target name\n",
    "\n",
    "    ''' Grid-Search Standard Kfold Cross Validation '''\n",
    "    # For each fold, a grid search cv is applied to find best params\n",
    "\n",
    "    def gscv(self,type_id='kfold'):\n",
    "\n",
    "        self.store_models = {} # Store models of Kfolds\n",
    "        self.dic_tr = {}\n",
    "        self.dic_te = {}\n",
    "\n",
    "        for model in self.models:\n",
    "\n",
    "            if(type_id is 'skfold'):\n",
    "                kfold = StratifiedKFold(n_splits=self.nfold,\n",
    "                                        shuffle=self.shuffle,\n",
    "                                        random_state=self.rs)\n",
    "            elif(type_id is 'kfold'):\n",
    "                kfold = KFold(n_splits=self.nfold,\n",
    "                              shuffle=self.shuffle,\n",
    "                              random_state=self.rs)\n",
    "\n",
    "            lst_temp = []; lst_temp2 = []; kfold_id = -1\n",
    "            for train_index, test_index in kfold.split(self.X,self.y):\n",
    "\n",
    "                kfold_id+=1;print(f'\\nkfold {kfold_id}')\n",
    "                # split data into train/test sets\n",
    "                X_train = self.X.iloc[train_index]\n",
    "                y_train = self.y[train_index]\n",
    "                X_test = self.X.iloc[test_index]\n",
    "                y_test = self.y[test_index]\n",
    "\n",
    "                # perform grid search to identify best hyper-parameters\n",
    "                gs_clf = GridSearchCV(model[1], param_grid=model[2],\n",
    "                                      cv=self.gsfold, n_jobs=1,\n",
    "                                      scoring='balanced_accuracy')\n",
    "\n",
    "                # Train using the best model\n",
    "                gs_clf.fit(X_train, y_train)\n",
    "                best_model = gs_clf.best_estimator_ # best cv model\n",
    "                self.store_models[f'GS_{model[0]}_{kfold_id}'] = best_model\n",
    "\n",
    "                # Predict using best model\n",
    "                ym_tr = gs_clf.predict(X_train)\n",
    "                ym_te = gs_clf.predict(X_test)\n",
    "                score_tr = balanced_accuracy_score(y_train,ym_tr)\n",
    "                score_te = balanced_accuracy_score(y_test,ym_te)\n",
    "                lst_temp.append(score_tr); lst_temp2.append(score_te)\n",
    "\n",
    "                print(f'Train Score: {round(score_tr,4)} - Test Score: {round(score_te,4)}')\n",
    "                print('Best hyperparameters for this fold')\n",
    "                print(gs_clf.best_params_)\n",
    "                print(f\"Test : Confusion matrix Fold {kfold_id}\")\n",
    "                print(confusion_matrix(y_test, ym_te))\n",
    "\n",
    "            self.dic_tr[model[0]] = lst_temp\n",
    "            self.dic_te[model[0]] = lst_temp2\n",
    "            test_mean = round(sum(lst_temp2)/len(lst_temp2),4)\n",
    "            print(f'\\n {model[0]} - Test Mean Score: {test_mean}')\n",
    "\n",
    "    '''K-Fold Cross Validation'''\n",
    "    # w/ type_id option; statified used to make sure classes are balanced in folds\n",
    "\n",
    "    def cv(self,type_id='kfold'):\n",
    "\n",
    "        print(f'type_id set to: {type_id}')\n",
    "        self.store_models = {} # Store models of Kfolds\n",
    "        self.dic_tr = {}\n",
    "        self.dic_te = {}\n",
    "\n",
    "        # Cycle though all tuple model settings\n",
    "        for model in self.models:\n",
    "\n",
    "            t0 = time.time()\n",
    "            if(type_id is 'skfold'):\n",
    "                kfold = StratifiedKFold(n_splits=self.nfold,\n",
    "                                        shuffle=self.shuffle,\n",
    "                                        random_state=self.rs)\n",
    "            elif(type_id is 'kfold'):\n",
    "                kfold = KFold(n_splits=self.nfold,\n",
    "                              shuffle=self.shuffle,\n",
    "                              random_state=self.rs)\n",
    "\n",
    "            lst_temp = []; lst_temp2 = []; kfold_id = -1\n",
    "            for train_index, test_index in kfold.split(self.X,self.y):\n",
    "\n",
    "                kfold_id+=1\n",
    "                # split data into train/test sets\n",
    "                X_train = self.X.iloc[train_index]\n",
    "                y_train = self.y[train_index]\n",
    "                X_test = self.X.iloc[test_index]\n",
    "                y_test = self.y[test_index]\n",
    "\n",
    "                # Fit, Stopre & Predict Kfold models\n",
    "                model[1].fit(X_train, y_train)\n",
    "                self.store_models[f'{model[0]}_{kfold_id}'] = model[1]\n",
    "                ym_tr = model[1].predict(X_train)\n",
    "                ym_te = model[1].predict(X_test)\n",
    "\n",
    "                score_tr = balanced_accuracy_score(y_train,ym_tr)\n",
    "                score_te = balanced_accuracy_score(y_test,ym_te)\n",
    "                lst_temp.append(score_tr); lst_temp2.append(score_te)\n",
    "\n",
    "            self.dic_tr[model[0]] = lst_temp\n",
    "            self.dic_te[model[0]] = lst_temp2\n",
    "            test_mean = round(sum(lst_temp2)/len(lst_temp2),4)\n",
    "            print(f'{model[0]} - Test Mean Score: {test_mean} - Total Time: {round(time.time() - t0,4)}')\n",
    "\n",
    "    ''' unitig visual functions only '''\n",
    "\n",
    "    def col_trans(self,sel_id=0):\n",
    "\n",
    "        # unitig to abrev\n",
    "        if(sel_id is 0):\n",
    "            self.X_names = self.X.columns.tolist()\n",
    "            temp_names = self.X_names.copy()\n",
    "\n",
    "            unitigs = self.X_names.copy()\n",
    "            del unitigs[-1]\n",
    "\n",
    "            lst_abr = []\n",
    "            ii=-1\n",
    "            for unitig in range(0,len(unitigs)):\n",
    "                ii+=1;lst_abr.append(f'u{ii}')\n",
    "            lst_abr.append(self.target_name)\n",
    "            self.X.columns = lst_abr\n",
    "            self.dicabr = dict(zip(lst_abr,self.X_names))\n",
    "\n",
    "        # abreb to unitig\n",
    "        elif(sel_id is 1):\n",
    "            self.X.columns = self.X_names\n",
    "\n",
    "    ''' PLOT KFOLD RESULTS '''\n",
    "\n",
    "    def fold_plot(self):\n",
    "\n",
    "        df_tr = pd.DataFrame(self.dic_tr)\n",
    "        df_te = pd.DataFrame(self.dic_te)\n",
    "\n",
    "        # Make Plots\n",
    "        fig,ax = plt.subplots(2,2,figsize=(14,6))\n",
    "        sns.stripplot(data=df_tr, orient='h',linewidth=1,ax=ax[0,0])\n",
    "        sns.heatmap(data=df_tr,annot=True,cbar=False,cmap=\"plasma_r\",\n",
    "                    vmax=1,vmin=0.5,ax=ax[0,1])\n",
    "        sns.stripplot(data=df_te, orient='h',linewidth=1,ax=ax[1,0])\n",
    "        sns.heatmap(data=df_te,annot=True,cbar=False,cmap=\"plasma_r\",\n",
    "                    vmax=1,vmin=0.5,fmt='.3g',ax=ax[1,1])\n",
    "        ax[0,0].set_xlim([0.5,1.1]);ax[1,0].set_xlim([0.5,1.1])\n",
    "        ax[0,0].set_title('train kfold')\n",
    "        ax[0,1].set_title('train kfold heatmap')\n",
    "        ax[1,0].set_title('test kfold')\n",
    "        ax[1,1].set_title('test kfold heatmap')\n",
    "        sns.despine(bottom=True, left=True)\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eJHdMmMQ29f",
   "metadata": {
    "id": "1eJHdMmMQ29f"
   },
   "source": [
    "# 6.Ciprofloxacin Resistance Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eCdMlauiREOu",
   "metadata": {
    "id": "eCdMlauiREOu"
   },
   "source": [
    "## 6.1.Model Summary\n",
    "\n",
    "* *Kfold Resistance Models* - Set benchmark model scores, outline promising models, quite different models are chosen to see which approaches work best for this problem\n",
    "* *GridSearchCV Resistance Models* - As one of the more well performing models that has feature importance as well, Let's try to improve the CatBoost model accuracy & check how kfold models differ when it comes to feature importance\n",
    "* *SVC Based Resistance Models* - SVC offers feature importance similar to LinearRegression(), we'll be able to know which top features favours which particular classes in terms of weighting, so if we can make sure the model performs well, we'll have some more unique insight on top of the tree based approach, so we'll try to tune the model so its as accurate as it can be so we have more confidence in the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FFdhHYzzRg01",
   "metadata": {
    "id": "FFdhHYzzRg01"
   },
   "source": [
    "## 6.2 K-FOLD Resistance Models\n",
    "\n",
    "**CHOOSING MODELS FOR EVALUATION**\n",
    "\n",
    "* We add models we would like to use for cross validation both unsupervised & supervised learning models.\n",
    "* Hyperparameter selections are quite arbitrary, tree based methods use n_estimators = 10, which doesn't seem like a bad place to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ygg-WNgR42r",
   "metadata": {
    "id": "9ygg-WNgR42r"
   },
   "outputs": [],
   "source": [
    "''' Define Models used for Testing '''\n",
    "models = []\n",
    "n_est = 10\n",
    "\n",
    "# Unsupervised Learning Models\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "\n",
    "# # Supervised Learning Models\n",
    "models.append(('SVC',SVC()))\n",
    "models.append(('TREE', DecisionTreeClassifier())) # Supervised Model\n",
    "models.append(('GBM', GradientBoostingClassifier(n_estimators=n_est)))\n",
    "\n",
    "# Desirable for Feature Importance Evaluation\n",
    "models.append(('XGB',XGBClassifier(n_estimators=n_est,verbosity = 0)))\n",
    "models.append(('CAT',CatBoostClassifier(silent=True,n_estimators=n_est)))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators=n_est)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V67-Rq6HU6-u",
   "metadata": {
    "id": "V67-Rq6HU6-u"
   },
   "source": [
    "**CASE INPUT**\n",
    "\n",
    "* Using the unmodified feature matrix of `get_unitigs().get_case()`\n",
    "* Using a standard 4-fold cross validation strategy, let's see how well the models perfom on each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T-TCG45nWZzs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T-TCG45nWZzs",
    "outputId": "926ff737-1992-480b-d098-bd08cfdca44a"
   },
   "outputs": [],
   "source": [
    "# Get case; (Dataset Feature Class)\n",
    "case = get_unitigs()\n",
    "case.get_case('cip_sr')\n",
    "\n",
    "# Standard KFOLD evaluation\n",
    "eval1 = class_eval(data=case, # input the case class\n",
    "                   nfold = 4, # 4 fold kfold\n",
    "                   models=models) # global models tuple list)\n",
    "\n",
    "# Evaluate kfold using selected models\n",
    "eval1.cv(type_id='kfold')  # standard kfold evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cxBSWZWxXWxl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "cxBSWZWxXWxl",
    "outputId": "b105d47d-528a-44ab-d5e7-a4cc11f37823"
   },
   "outputs": [],
   "source": [
    "eval1.fold_plot()  # plot kfold results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zZD9x4btYn6H",
   "metadata": {
    "id": "zZD9x4btYn6H"
   },
   "source": [
    "For predicting ciprofloxacin resistance, the most reliable and consistent models are CatBoost (CAT), XGBoost (XGB), Gradient Boosting (GBM), and Random Forest (RF), all showing high and stable performance across test folds. In contrast, LDA performs poorly with low and unstable test scores, making it unsuitable for this task. Models like Naive Bayes (NB) also show variance between folds, indicating a potential need for hyperparameter tuning or regularization to improve generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58xoygh3Yuhn",
   "metadata": {
    "id": "58xoygh3Yuhn"
   },
   "source": [
    "**TREE BASED FEATURE IMPORTANCE**\n",
    "\n",
    "* Using *RandomForest*,*CatBoost*,*XGBRegressor* we have access to the model's relative feature importance\n",
    "* It's useful to compare the feature importance of multiple models together. We have over 8000 unitigs; let's pick the top 10 most influential.\n",
    "* The most critical unitigs to the determination of antibiotic resistance (according to the model) are saved in BioPython Seq format & can be used for further analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7IqGPd8WYqZh",
   "metadata": {
    "id": "7IqGPd8WYqZh"
   },
   "outputs": [],
   "source": [
    "''' Tree Based Feature Importance '''\n",
    "# requires evaluation class input w/ at least one of RF, CatBoost & XGB moedls\n",
    "# models stored in .store_models are required from eval class\n",
    "\n",
    "class fi:\n",
    "\n",
    "    def __init__(self,data=None, # evaluation class\n",
    "                      sort_by='RF', # show most important features\n",
    "                      max_features=10 # limit unitigs to\n",
    "                ):\n",
    "\n",
    "        if(data is None):\n",
    "            print('Enter Evaluation class w/ CAT,RF,XGB')\n",
    "        else:\n",
    "            evals = data\n",
    "            # check which models are present\n",
    "            lst_models = list(evals.store_models.keys())\n",
    "            temp = []\n",
    "            for i in lst_models:\n",
    "                if('CAT' in i):\n",
    "                    temp.append('CAT')\n",
    "                if('RF' in i):\n",
    "                    temp.append('RF')\n",
    "                if('XGB' in i):\n",
    "                    temp.append('XGB')\n",
    "\n",
    "            # input contains gscv data\n",
    "            if('GS' in lst_models[0]):\n",
    "                self.gs_id = True\n",
    "            else:\n",
    "                self.gs_id = False\n",
    "\n",
    "        self.lst_tree_models = list(set(temp))\n",
    "\n",
    "        self.evals = data  # evaluation class\n",
    "        self.lst_Seqs = []  # list of important unitigs\n",
    "        self.max_features = max_features # show top n features\n",
    "        self.sort_by = sort_by # sort by particualr model fi, other mods show this index only\n",
    "        self.abr_feat = False # activate if unitig names are too big for figure\n",
    "\n",
    "    # Compile all Tree based feature importance results\n",
    "    def get(self):\n",
    "\n",
    "        # USL scaling\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "        # Recall Model & Get Feature Importance from data class\n",
    "        # unless gridsearched, all kfolds are the same model\n",
    "\n",
    "        ii=-1\n",
    "        # if randomforest models are present\n",
    "        if('RF' in self.lst_tree_models):\n",
    "\n",
    "            if(self.gs_id):\n",
    "\n",
    "                # fold names\n",
    "                tlst_models = [f'GS_RF_{i}' for i in range(0,self.evals.nfold)]\n",
    "\n",
    "                # stack all fold results\n",
    "                for kfold_id in tlst_models:\n",
    "                    ii+=1\n",
    "                    rf_model = self.evals.store_models[kfold_id]\n",
    "                    imp_rf = rf_model.feature_importances_\n",
    "                    rf_sc = min_max_scaler.fit_transform(imp_rf[:,None])\n",
    "                    ldf = pd.DataFrame(rf_sc,index=self.evals.X.columns,columns=[kfold_id])\n",
    "                    if(ii is 0):\n",
    "                        df = ldf.copy()\n",
    "                    else:\n",
    "                        df = pd.concat([df,ldf],axis=1)\n",
    "\n",
    "            else:\n",
    "\n",
    "                ii+=1\n",
    "                rf_model = self.evals.store_models['RF_1']\n",
    "                imp_rf = rf_model.feature_importances_\n",
    "                rf_sc = min_max_scaler.fit_transform(imp_rf[:,None])\n",
    "                ldf = pd.DataFrame(rf_sc,index=self.evals.X.columns,columns=['RF'])\n",
    "                if(ii is 0):\n",
    "                    df = ldf.copy()\n",
    "                else:\n",
    "                    df = pd.concat([df,ldf],axis=1)\n",
    "\n",
    "        # if catboost models are present\n",
    "        if('CAT' in self.lst_tree_models):\n",
    "\n",
    "            if(self.gs_id):\n",
    "\n",
    "                # fold names\n",
    "                tlst_models = [f'GS_CAT_{i}' for i in range(0,self.evals.nfold)]\n",
    "\n",
    "                # stack all fold results\n",
    "                for kfold_id in tlst_models:\n",
    "                    ii+=1\n",
    "                    cb_model = self.evals.store_models[kfold_id]\n",
    "                    imp_cb = cb_model.get_feature_importance()\n",
    "                    cb_sc = min_max_scaler.fit_transform(imp_cb[:,None])\n",
    "                    ldf = pd.DataFrame(cb_sc,index=self.evals.X.columns,columns=[kfold_id])\n",
    "                    if(ii is 0):\n",
    "                        df = ldf.copy()\n",
    "                    else:\n",
    "                        df = pd.concat([df,ldf],axis=1)\n",
    "\n",
    "            else:\n",
    "                ii+=1\n",
    "                cb_model = self.evals.store_models['CAT_1']\n",
    "                imp_cb = cb_model.get_feature_importance()\n",
    "                cb_sc = min_max_scaler.fit_transform(imp_cb[:,None])\n",
    "                ldf = pd.DataFrame(cb_sc,index=self.evals.X.columns,columns=['CB'])\n",
    "                if(ii is 0):\n",
    "                    df = ldf.copy()\n",
    "                else:\n",
    "                    df = pd.concat([df,ldf],axis=1)\n",
    "\n",
    "\n",
    "        if('XGB' in self.lst_tree_models):\n",
    "\n",
    "            if(self.gs_id):\n",
    "\n",
    "                # fold names\n",
    "                tlst_models = [f'GS_XGB_{i}' for i in range(0,self.evals.nfold)]\n",
    "\n",
    "                # stack all fold results\n",
    "                for kfold_id in tlst_models:\n",
    "                    ii+=1\n",
    "                    xg_model = self.evals.store_models[kfold_id]\n",
    "                    imp_xg = xg_model.feature_importances_\n",
    "                    xg_sc = min_max_scaler.fit_transform(imp_xg[:,None])\n",
    "                    ldf = pd.DataFrame(xg_sc,index=self.evals.X.columns,columns=[kfold_id])\n",
    "                    if(ii is 0):\n",
    "                        df = ldf.copy()\n",
    "                    else:\n",
    "                        df = pd.concat([df,ldf],axis=1)\n",
    "\n",
    "            else:\n",
    "\n",
    "                ii+=1\n",
    "                xg_model = self.evals.store_models['XGB_1']\n",
    "                imp_xg = xg_model.feature_importances_\n",
    "                xg_sc = min_max_scaler.fit_transform(imp_xg[:,None])\n",
    "                ldf = pd.DataFrame(rf_sc,index=self.evals.X.columns,columns=['XGB'])\n",
    "\n",
    "                if(ii is 0):\n",
    "                    df = ldf.copy()\n",
    "                else:\n",
    "                    df = pd.concat([df,ldf],axis=1)\n",
    "\n",
    "        # change to abbrev if names are too long to display\n",
    "        if(self.abr_feat):\n",
    "            self.evals.col_trans(0)\n",
    "\n",
    "        # Sort by one of the available columns\n",
    "        df.sort_values(by=self.sort_by,ascending=False,inplace=True)\n",
    "\n",
    "        if(self.abr_feat):\n",
    "                self.evals.col_trans(1)\n",
    "\n",
    "        # show only most critical features in FI\n",
    "        subset = df[:self.max_features]\n",
    "\n",
    "#       Store the most important features\n",
    "        for i in subset.index.tolist():\n",
    "            self.lst_Seqs.append(Seq(i))\n",
    "\n",
    "        # Plot features\n",
    "        fig = px.bar(subset,orientation='h')\n",
    "        fig.update_traces(width=0.5)\n",
    "        fig.update_layout(height=400,template='plotly_white',\n",
    "                          title=f\"<b>FEATURE IMPORTANCE</b> | Sorted by {self.sort_by}()\")\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67pAgiENZ2cA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "67pAgiENZ2cA",
    "outputId": "f299b9f1-8688-48a0-f3ea-d5252bfcf013"
   },
   "outputs": [],
   "source": [
    "crit_unitigs = fi(data=eval1,sort_by='CB')\n",
    "crit_unitigs.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n89vhMd4Z-y8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n89vhMd4Z-y8",
    "outputId": "836ec6f3-dd33-4a5c-e587-de2364045d0c"
   },
   "outputs": [],
   "source": [
    "crit_unitigs.lst_Seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qiupf1U5a-3b",
   "metadata": {
    "id": "qiupf1U5a-3b"
   },
   "source": [
    "## 6.3. GridSearchCV Resistance Model\n",
    "\n",
    "**CATBOOST HYPERPARAMETER TUNING**\n",
    "\n",
    "* We saw that *CatboostClassifier* had already has quite good results on the test set, let's try to optimise the hyperparameters, if we can.\n",
    "* Catboost does optimise certain parameters that aren't self defined, so we may not get any improvement, however we should get different hyerparameter combinations on different folds, which will be handy to check if there is any feature importance variation.\n",
    "\n",
    "**GETTING ALL MODELS PARAMETERS**\n",
    "\n",
    "* We can call `.get_all_params()` to display all the parameters that were set in CatBoost, on top of the n_estimators that we set ourselves.\n",
    "* The learning rate & n_estimators/iterations are two hyperparameters we can try to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jZT4tcUVbb2k",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jZT4tcUVbb2k",
    "outputId": "6acb921b-adb4-44ee-80bf-241370974bc9"
   },
   "outputs": [],
   "source": [
    "# Show default parameters used in catboost model\n",
    "eval1.store_models['CAT_0'].get_all_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3jQrdXcHxR",
   "metadata": {
    "id": "be3jQrdXcHxR"
   },
   "source": [
    "DEFINING GRID & GRIDSEARCHCV\n",
    "\n",
    "* We define a parameter grid, which will be used in GridSearchCV; keeping it simple, looking at only n_estimators (iters) & the learning rate.\n",
    "* Defining a standard 4-fold cross validation strategy once again, we should get 4 slightly different models this time, which are stored in .store_models().\n",
    "* Catboost is of course compatible with the GPU, so we can set task_type = \"GPU\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1-RWFMWAkrpB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1-RWFMWAkrpB",
    "outputId": "196f0566-6119-4d97-9a12-8f8be2a62f4b"
   },
   "outputs": [],
   "source": [
    "# Define Grid used in Cross Validation\n",
    "params = {'n_estimators':[10,25,40],\n",
    "         'learning_rate':[0.01,0.05,0.5]}\n",
    "\n",
    "# Define Model (just the one)\n",
    "models = []\n",
    "models.append(('CAT', CatBoostClassifier(silent=True,\n",
    "                                         task_type=\"GPU\"),params))\n",
    "\n",
    "# Get Dataset Features\n",
    "case2 = get_unitigs()\n",
    "case2.get_case('cip_sr')\n",
    "\n",
    "eval2 = class_eval(data=case2,\n",
    "                   models=models)\n",
    "eval2.gscv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Bj_PhSjG4wQ0",
   "metadata": {
    "id": "Bj_PhSjG4wQ0"
   },
   "source": [
    "**PLOTTING KFOLD MODEL FEATURE IMPORTANCES**\n",
    "\n",
    "* Passing on an eval class instance into class fi, we have access to store_models, which when using the gridsearchcv option in class eval stores the fold models.\n",
    "* Unlike .cv(), we probably will have slightly different model hyperparameters for each fold, feature importance of these models can also be visualised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q-_vRjOi45ti",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "q-_vRjOi45ti",
    "outputId": "2d65f67a-fd15-4968-d067-ee12853f0b8d"
   },
   "outputs": [],
   "source": [
    "crit_unitigs = fi(data=eval2,sort_by='GS_CAT_0')\n",
    "crit_unitigs.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aOWyPuXB48vG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aOWyPuXB48vG",
    "outputId": "226ae9e3-d7bb-416e-fb16-881f793859e1"
   },
   "outputs": [],
   "source": [
    "crit_unitigs.lst_Seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IaV5ZaMv4_E1",
   "metadata": {
    "id": "IaV5ZaMv4_E1"
   },
   "source": [
    "**REVISITING UNITIG DISTRIBUTIONS**\n",
    "\n",
    "* Having identified the key features (unitigs) which have the most weight in its respective model\n",
    "* With tree based model feature importance, we ultimately get only positive values & don't have an indication about which class the result is leaning towards\n",
    "* However knowing which features features (unitigs) to look at now, we can use group_by to get some idea since they are all of One Hot Encoding type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CI9t7MZz5MgL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CI9t7MZz5MgL",
    "outputId": "63014fb0-813c-4eda-ca16-ebed56b776b9"
   },
   "outputs": [],
   "source": [
    "case = get_unitigs()\n",
    "case.get_case('cip_sr')\n",
    "\n",
    "print(case.X.groupby('cip_sr')['GTGCGACAGCAAAGTCCAAACCAGCGTCCCCGCC'].mean())\n",
    "print(case.X.groupby('cip_sr')['GCGCAGCCGCAAATCTTGTTTTCCCATTCCGCC'].mean())\n",
    "print(case.X.groupby('cip_sr')['AAATTGCGGATCGATGCGCGAAGGGTCGAATGC'].mean())\n",
    "\n",
    "print(case.X.groupby('cip_sr')['GGCATCCCGAAGCCGAATACGGCAACGGCAAGCG'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc2kbug5YfX",
   "metadata": {
    "id": "5fc2kbug5YfX"
   },
   "source": [
    "## 6.4 SVC Model Resistance Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11pesbz5fH_",
   "metadata": {
    "id": "f11pesbz5fH_"
   },
   "source": [
    "**SVC SUBOPTIMAL MODEL**\n",
    "\n",
    "* In previous section, we used the SVC model, using the default hyperparameters, which uses kernel='rbf'\n",
    "* SVC gives us the option to evaluate the feature importance of weights, if we use kernel='linear'\n",
    "* Unlike the tree based feature importance, we will know towards which class the particular feature leans towards (importance wise)\n",
    "* Let's try a default model first, followed by a gridsearchcv optimised model, so we can see if there is any difference in feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C86-7ek96uMR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C86-7ek96uMR",
    "outputId": "2dc18193-7554-4dce-f9ba-29a0a42acd69"
   },
   "outputs": [],
   "source": [
    "''' Define Models used for Testing '''\n",
    "models = []\n",
    "models.append(('SVC',SVC(kernel = 'linear')))\n",
    "\n",
    "# Get case; (Dataset Feature Class)\n",
    "case = get_unitigs()\n",
    "case.get_case('cip_sr')\n",
    "\n",
    "# Standard KFOLD evaluation\n",
    "eval_svc1 = class_eval(data=case, # input the case class\n",
    "                   nfold = 4, # 4 fold kfold\n",
    "                   models=models) # global models tuple list)\n",
    "\n",
    "# Evaluate kfold using selected models\n",
    "eval_svc1.cv(type_id='kfold')  # standard kfold evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Knn_e6A1DHBQ",
   "metadata": {
    "id": "Knn_e6A1DHBQ"
   },
   "outputs": [],
   "source": [
    "''' Function plots & returns highest weighted features '''\n",
    "# for SVC linear covariance function model in SQ sequence format\n",
    "\n",
    "def fi_svc(classifier, feature_names, top_features=5,verbose=False):\n",
    "\n",
    "    coef = classifier.coef_.ravel()\n",
    "    top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
    "    top_negative_coefficients = np.argsort(coef)[:top_features]\n",
    "    top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
    "\n",
    "    # plt.title(\"Feature Importances (Support Vector Machine) - Ciprofloxacin Resistance\", y=1.08)\n",
    "    colors = ['crimson' if c < 0 else 'cornflowerblue' for c in coef[top_coefficients]]\n",
    "    feature_names = np.array(feature_names)\n",
    "    lser = pd.Series(data=coef[top_coefficients],index=feature_names[top_coefficients])\n",
    "    fig = px.bar(lser,orientation='h')\n",
    "    fig.update_traces(width=0.5)\n",
    "    fig.update_layout(height=350,template='plotly_white',showlegend=False,\n",
    "                        title=f\"<b>FEATURE IMPORTANCE</b> | SVC\")\n",
    "    fig.show()\n",
    "\n",
    "    # if we print the unitigs, we can then look at what genes they relate to\n",
    "    top_negative_coefficients = np.argsort(coef)[:5]\n",
    "    neg_predictors = np.asarray(feature_names)[top_negative_coefficients]\n",
    "    top_positive_coefficients = np.argsort(coef)[-5:]\n",
    "    pos_predictors = np.asarray(feature_names)[top_positive_coefficients]\n",
    "    if(verbose):\n",
    "        print(\"Top negative predictors: \",neg_predictors)\n",
    "        print(\"Top positive predictors: \",pos_predictors)\n",
    "\n",
    "    # Store the most important features\n",
    "    top_negSeq = []; top_posSeq = []\n",
    "    for i in range(0,top_features):\n",
    "        top_negSeq.append(Seq(neg_predictors[i]))\n",
    "        top_posSeq.append(Seq(pos_predictors[i]))\n",
    "\n",
    "    return top_negSeq, top_posSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcxTJxwxC8R_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bcxTJxwxC8R_",
    "outputId": "411ad4f6-3222-488d-bf37-ebdf80191170"
   },
   "outputs": [],
   "source": [
    "eval_svc1.store_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imejBPBvDBRa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "imejBPBvDBRa",
    "outputId": "ef32b8db-2bf4-4582-be48-cf18efacae8d"
   },
   "outputs": [],
   "source": [
    "neg_predictors,pos_predictors = fi_svc(eval_svc1.store_models['SVC_3'], list(eval_svc1.X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Cs8WmzlNDM6H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cs8WmzlNDM6H",
    "outputId": "b455fe7c-0b97-4f9f-cf47-9cc2774c1753"
   },
   "outputs": [],
   "source": [
    "# return list of sequences list ordered from most to least important\n",
    "neg_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JHxeRrwrDPcc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JHxeRrwrDPcc",
    "outputId": "e6dcf00f-11ea-4714-9683-210999669ef7"
   },
   "outputs": [],
   "source": [
    "# return list of sequences ordered from least to most important\n",
    "pos_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UrLTvPhqQC5F",
   "metadata": {
    "id": "UrLTvPhqQC5F"
   },
   "source": [
    "**SVC OPTIMISED MODEL**\n",
    "\n",
    "* The linear covariance function model performed a little worse than those tested in the previous section\n",
    "* Let's see if we can optimise the model a little bit & check if the same features will remain the most important in the model\n",
    "* Let's try a variation in the gamma hyperparameter for the search grid to keep things quite simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "J45vv3l9QIAd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J45vv3l9QIAd",
    "outputId": "c1ae62d0-cf30-4055-a159-ba3e914561e0"
   },
   "outputs": [],
   "source": [
    "svm_params = {\n",
    "    'C': [0.01],\n",
    "    'gamma': [1e-06, 1e-05],\n",
    "    'kernel': ['linear']\n",
    "}\n",
    "\n",
    "# Define Model (just the one)\n",
    "svm = SVC(class_weight='balanced')\n",
    "models = []\n",
    "models.append(('SVM',svm,svm_params))\n",
    "\n",
    "# Get Dataset Features\n",
    "case = get_unitigs()\n",
    "case.get_case('cip_sr')\n",
    "\n",
    "eval_svc2 = class_eval(data=case,\n",
    "                   models=models)\n",
    "eval_svc2.gscv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hCKEEVZQTBCT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hCKEEVZQTBCT",
    "outputId": "9eb4c4b8-1569-406d-8ab4-62b9dc3a1406"
   },
   "outputs": [],
   "source": [
    "eval_svc2.store_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sb73KjAaTCvm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "sb73KjAaTCvm",
    "outputId": "77117f83-f606-4d18-b736-068c65dd02ae"
   },
   "outputs": [],
   "source": [
    "neg_predictors,pos_predictors = fi_svc(eval_svc2.store_models['GS_SVM_0'], list(eval_svc2.X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ksgoVgnyTFKf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ksgoVgnyTFKf",
    "outputId": "6b8715c3-e968-41a9-c075-f3cbbee2103d"
   },
   "outputs": [],
   "source": [
    "# return list of sequences list ordered from most to least important\n",
    "neg_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8HqmaNskTG2W",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8HqmaNskTG2W",
    "outputId": "e773de35-1bb0-4611-d599-f5c8fad098af"
   },
   "outputs": [],
   "source": [
    "# return list of sequences ordered from least to most important\n",
    "pos_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ooPCU3prcg3-",
   "metadata": {
    "id": "ooPCU3prcg3-"
   },
   "source": [
    "## 6.5 Cefixime Resistance – Model Evaluation Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Mqg3aUNqcnsB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 915
    },
    "id": "Mqg3aUNqcnsB",
    "outputId": "40b8cefd-be95-4d11-a1ba-8d5262af11e9"
   },
   "outputs": [],
   "source": [
    "# 1. K-Fold sonuçlarını DataFrame’e çevir\n",
    "df_tr_cip = pd.DataFrame(eval1.dic_tr)\n",
    "df_te_cip = pd.DataFrame(eval1.dic_te)\n",
    "\n",
    "# 2. Ortalama skorları hesapla\n",
    "summary_cip = pd.DataFrame({\n",
    "    \"Model\": df_te_cip.columns,\n",
    "    \"Train Mean Balanced Accuracy\": df_tr_cip.mean().values,\n",
    "    \"Test Mean Balanced Accuracy\": df_te_cip.mean().values\n",
    "}).sort_values(\"Test Mean Balanced Accuracy\", ascending=False)\n",
    "\n",
    "# 3. Tabloyu göster\n",
    "display(summary_cip)\n",
    "\n",
    "# 4. Grafikle görselleştir\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=summary_cip, x=\"Test Mean Balanced Accuracy\", y=\"Model\", palette=\"Oranges_d\")\n",
    "plt.title(\"Classifier Performance on Ciprofloxacin Resistance (Test Balanced Accuracy)\", fontsize=14)\n",
    "plt.xlabel(\"Mean Balanced Accuracy (Test)\")\n",
    "plt.ylabel(\"Model\")\n",
    "plt.xlim(0.5, 1.0)\n",
    "plt.grid(True, axis='x', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r8KBjqYj9Y5p",
   "metadata": {
    "id": "r8KBjqYj9Y5p"
   },
   "source": [
    "## 6.6 Ciprofloxacin Resistance – SHAP Explainability (CAT Model)\n",
    "\n",
    "The CatBoost classifier, which achieved the highest test balanced accuracy (0.9694) for Ciprofloxacin resistance prediction, was further analyzed using SHAP (SHapley Additive exPlanations) to interpret feature contributions.\n",
    "\n",
    "The **global explainability** analysis, presented through SHAP summary and bar plots, highlights the most influential genomic unitigs contributing to resistance classification. These insights help identify the genomic signatures most associated with Ciprofloxacin resistance.\n",
    "\n",
    "Additionally, **local explanations** illustrate how specific features drive individual predictions, providing a clearer understanding of the classifier’s decision-making process for selected cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GIsveqrV90-r",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "GIsveqrV90-r",
    "outputId": "3adae3e2-2d25-4e05-f3d1-9649a8049099"
   },
   "outputs": [],
   "source": [
    "# 1) Choosing the CAT Model which is Higher Score\n",
    "cat_keys = [k for k in getattr(eval1, \"store_models\", {}).keys() if k.startswith(\"GS_CAT_\")] \\\n",
    "           or [k for k in getattr(eval1, \"store_models\", {}).keys() if k.startswith(\"CAT_\")]\n",
    "if not cat_keys:\n",
    "    raise RuntimeError(\"CatBoost modeli bulunamadı. Lütfen Ciprofloxacin için CAT modeli eğitildiğinden emin olun.\")\n",
    "\n",
    "cat_key = sorted(cat_keys)[0]\n",
    "cat_model = eval1.store_models[cat_key]\n",
    "\n",
    "# 2) Feature Matrix\n",
    "X_cip = eval1.X.drop(columns=[eval1.target_name], errors=\"ignore\")\n",
    "\n",
    "# 3) TreeExplainer + SHAP Values\n",
    "explainer = shap.TreeExplainer(cat_model)\n",
    "shap_values = explainer.shap_values(X_cip)\n",
    "\n",
    "# 4) Beeswarm\n",
    "plt.figure(figsize=(10, 6))\n",
    "try:\n",
    "    shap.summary_plot(shap_values[1], X_cip, show=False)  # ikili sınıfta pozitif sınıf\n",
    "except Exception:\n",
    "    shap.summary_plot(shap_values, X_cip, show=False)\n",
    "plt.title(\"SHAP Summary – Ciprofloxacin / CAT\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "print(\"---------------------------------\")\n",
    "print(\"---------------------------------\")\n",
    "print(\"---------------------------------\")\n",
    "print(\"---------------------------------\")\n",
    "\n",
    "# 5) Bar (mean |SHAP|)\n",
    "plt.figure(figsize=(10, 6))\n",
    "try:\n",
    "    shap.summary_plot(shap_values[1], X_cip, plot_type=\"bar\", show=False)\n",
    "except Exception:\n",
    "    shap.summary_plot(shap_values, X_cip, plot_type=\"bar\", show=False)\n",
    "plt.title(\"Mean |SHAP| – Ciprofloxacin / CAT\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I1ldSCudAnLW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "I1ldSCudAnLW",
    "outputId": "cd9dec44-5aae-423a-a135-d06d0ae08b60"
   },
   "outputs": [],
   "source": [
    "# Optional: Top 10 Features Table\n",
    "try:\n",
    "    sv = shap_values[1] if isinstance(shap_values, list) else shap_values\n",
    "    imp = np.abs(sv).mean(axis=0)\n",
    "    top10 = pd.DataFrame({\"feature\": X_cip.columns, \"mean_abs_shap\": imp}).sort_values(\n",
    "        \"mean_abs_shap\", ascending=False\n",
    "    ).head(10).reset_index(drop=True)\n",
    "    display(top10)\n",
    "except Exception as e:\n",
    "    print(\"Top10 tablo üretilemedi:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u5qGcqHtQOaM",
   "metadata": {
    "id": "u5qGcqHtQOaM"
   },
   "source": [
    "## 6.7 Cefixime Resistance – LIME Explainability (GBM Model)\n",
    "In this section, we interpret the best-performing Cefixime model (GBM) using LIME (model-agnostic, local explanations). The procedure selects the trained GBM from the evaluation pipeline, builds a tabular explainer on the feature matrix (target removed), and explains a chosen instance (default: index 0). We visualize the weighted feature contributions and list the top-k influential unitigs for that prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_j7xnTe5QTY7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 856
    },
    "id": "_j7xnTe5QTY7",
    "outputId": "13f2468f-930d-44c8-9f29-e5d022f824d6"
   },
   "outputs": [],
   "source": [
    "# 1) Pick the CAT model key (prefer GS_CAT_* over CAT_*)\n",
    "cat_keys = [k for k in getattr(eval1, \"store_models\", {}).keys() if k.startswith(\"GS_CAT_\")] \\\n",
    "           or [k for k in getattr(eval1, \"store_models\", {}).keys() if k.startswith(\"CAT_\")]\n",
    "if not cat_keys:\n",
    "    raise RuntimeError(\"No CatBoost model found for Ciprofloxacin. Please run the CAT training cells first.\")\n",
    "cat_key   = sorted(cat_keys)[0]\n",
    "cat_model = eval1.store_models[cat_key]\n",
    "\n",
    "# 2) Build the feature matrix (drop target) and class names\n",
    "X_cip = eval1.X.drop(columns=[eval1.target_name], errors=\"ignore\").copy()\n",
    "y_cip = getattr(eval1, \"y\", None)\n",
    "class_names = [\"0\",\"1\"] if y_cip is None else [str(c) for c in sorted(pd.unique(y_cip))]\n",
    "\n",
    "# 3) Create a LIME tabular explainer on the training data\n",
    "explainer = LimeTabularExplainer(\n",
    "    training_data=X_cip.values,\n",
    "    feature_names=X_cip.columns.tolist(),\n",
    "    class_names=class_names,\n",
    "    mode=\"classification\",\n",
    "    discretize_continuous=True\n",
    ")\n",
    "\n",
    "# 4) Choose an instance to explain and define predict_fn\n",
    "instance_idx = 0          # change as needed (e.g., 10, 25, ...)\n",
    "num_features = 10         # number of top contributing features to list\n",
    "num_samples  = 5000       # number of synthetic samples LIME will generate\n",
    "\n",
    "x0 = X_cip.iloc[instance_idx].values\n",
    "predict_fn = lambda data: cat_model.predict_proba(pd.DataFrame(data, columns=X_cip.columns))\n",
    "\n",
    "# 5) Generate the explanation and visualize it\n",
    "exp = explainer.explain_instance(\n",
    "    data_row=x0,\n",
    "    predict_fn=predict_fn,\n",
    "    num_features=num_features,\n",
    "    num_samples=num_samples\n",
    ")\n",
    "\n",
    "fig = exp.as_pyplot_figure()\n",
    "_ = fig.suptitle(f\"LIME Explanation – Ciprofloxacin / CAT – {cat_key} – idx={instance_idx}\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# 6) Human-readable list (feature rule, weight) + DataFrame\n",
    "pairs = exp.as_list()  # [(feature_rule, weight), ...]\n",
    "print(f\"\\nTop {num_features} features (LIME weights):\")\n",
    "for f, w in pairs:\n",
    "    print(f\"{f}  ==>  {w:+.4f}\")\n",
    "\n",
    "top_df = pd.DataFrame(pairs, columns=[\"feature_rule\", \"lime_weight\"])\n",
    "display(top_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "S4AtkupiYh4W",
   "metadata": {
    "id": "S4AtkupiYh4W"
   },
   "source": [
    "# 7.Azithromycin Resistance Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dx2jwND_ZTqS",
   "metadata": {
    "id": "dx2jwND_ZTqS"
   },
   "source": [
    "## 7.1 Load and summarise azm_sr dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OcpqBJLBZVnp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OcpqBJLBZVnp",
    "outputId": "f905f16f-f67b-4475-e63a-7f213ca84b4c"
   },
   "outputs": [],
   "source": [
    "case_azm = get_unitigs()\n",
    "case_azm.get_case('azm_sr')\n",
    "print(case_azm.X[case_azm.target_name].value_counts())\n",
    "print(\"Shape:\", case_azm.X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p7yV8xOqbztP",
   "metadata": {
    "id": "p7yV8xOqbztP"
   },
   "source": [
    "## 7.2 Class re-balancing with SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UxIwM8n9cF4n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UxIwM8n9cF4n",
    "outputId": "1727c25a-77b9-424a-81ae-f6142599d409"
   },
   "outputs": [],
   "source": [
    "mod_azm = mod_unitigs(case_azm)\n",
    "mod_azm.smote(smote_id='smotenc',\n",
    "              smote_strat=0.5,\n",
    "              k_neighbours=5)\n",
    "print(mod_azm.X[mod_azm.target_name].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kL0I--qzcNsM",
   "metadata": {
    "id": "kL0I--qzcNsM"
   },
   "source": [
    "## 7.3 Model roster & 4-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xSjpMkfXcRv9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xSjpMkfXcRv9",
    "outputId": "8a6891d4-f038-4ec0-85f6-4788ac552e47"
   },
   "outputs": [],
   "source": [
    "models_azm = []\n",
    "n_est = 10\n",
    "models_azm += [\n",
    "    ('LDA', LinearDiscriminantAnalysis()),\n",
    "    ('KNN', KNeighborsClassifier()),\n",
    "    ('NB',  GaussianNB()),\n",
    "    ('SVC', SVC()),\n",
    "    ('TREE', DecisionTreeClassifier()),\n",
    "    ('GBM', GradientBoostingClassifier(n_estimators=n_est)),\n",
    "    ('XGB', XGBClassifier(n_estimators=n_est, verbosity=0)),\n",
    "    ('CAT', CatBoostClassifier(silent=True, n_estimators=n_est)),\n",
    "    ('RF',  RandomForestClassifier(n_estimators=n_est))\n",
    "]\n",
    "eval_azm = class_eval(data=mod_azm, models=models_azm, nfold=4)\n",
    "eval_azm.cv(type_id='kfold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G5t5Hm52ci-I",
   "metadata": {
    "id": "G5t5Hm52ci-I"
   },
   "source": [
    "## 7.5 SVC GridSearch + coef analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hczIrB15clxw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hczIrB15clxw",
    "outputId": "0405eebd-3bdf-4b58-954a-51dfdae9fd32"
   },
   "outputs": [],
   "source": [
    "svc_params = {'C':[0.01,0.1,1,10],\n",
    "              'gamma':[1e-4,1e-5],\n",
    "              'kernel':['linear']}\n",
    "gs_svc = [('SVC', SVC(class_weight='balanced'), svc_params)]\n",
    "eval_azm_svc = class_eval(data=mod_azm, models=gs_svc, nfold=4,\n",
    "                          shuffle_id=True, random_state=42)\n",
    "eval_azm_svc.gscv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KqBcJRiMdS7N",
   "metadata": {
    "id": "KqBcJRiMdS7N"
   },
   "source": [
    "## 7.6 Azithromycin Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pur1dMrPdXDo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "pur1dMrPdXDo",
    "outputId": "2129fa05-a4d5-4e0e-88a5-7a194fa83492"
   },
   "outputs": [],
   "source": [
    "neg_seq_azm, pos_seq_azm = fi_svc(\n",
    "    eval_azm_svc.store_models['GS_SVC_0'],\n",
    "    list(eval_azm_svc.X.columns),\n",
    "    top_features=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h2VhzRkolMSH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h2VhzRkolMSH",
    "outputId": "9375b973-ee5c-463e-b6f9-08535f487cad"
   },
   "outputs": [],
   "source": [
    "neg_seq_azm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j6OpT1DWlOUR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j6OpT1DWlOUR",
    "outputId": "0061b8ea-3dbb-46f0-b69f-cb9eb1fb0276"
   },
   "outputs": [],
   "source": [
    "pos_seq_azm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8vHdHA8dGYa",
   "metadata": {
    "id": "e8vHdHA8dGYa"
   },
   "source": [
    "## 7.7 Azithromycin Resistance – Model Evaluation Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3AkrGBDZdMeh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 915
    },
    "id": "3AkrGBDZdMeh",
    "outputId": "8e8a96af-dac4-4193-d41c-91ee0c3cf793"
   },
   "outputs": [],
   "source": [
    "# 1. Skor sözlüklerini DataFrame’e çevir\n",
    "df_tr_azm = pd.DataFrame(eval_azm.dic_tr)\n",
    "df_te_azm = pd.DataFrame(eval_azm.dic_te)\n",
    "\n",
    "# 2. Ortalama skorları hesapla\n",
    "summary_azm = pd.DataFrame({\n",
    "    \"Model\": df_te_azm.columns,\n",
    "    \"Train Mean Balanced Accuracy\": df_tr_azm.mean().values,\n",
    "    \"Test Mean Balanced Accuracy\": df_te_azm.mean().values\n",
    "}).sort_values(\"Test Mean Balanced Accuracy\", ascending=False)\n",
    "\n",
    "# 3. Tabloyu göster\n",
    "display(summary_azm)\n",
    "\n",
    "# 4. Grafikle görselleştir\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=summary_azm, x=\"Test Mean Balanced Accuracy\", y=\"Model\", palette=\"Greens_d\")\n",
    "plt.title(\"Classifier Performance on Azithromycin Resistance (Test Balanced Accuracy)\", fontsize=14)\n",
    "plt.xlabel(\"Mean Balanced Accuracy (Test)\")\n",
    "plt.ylabel(\"Model\")\n",
    "plt.xlim(0.5, 1.0)\n",
    "plt.grid(True, axis='x', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QMd4RcHwO1Rf",
   "metadata": {
    "id": "QMd4RcHwO1Rf"
   },
   "source": [
    "## 7.8 Azithromycin SHAP Explainability (LDA Model)\n",
    "\n",
    "In this section, we interpret the best-performing model for Azithromycin resistance prediction using SHAP.  \n",
    "From the model evaluation results, **Linear Discriminant Analysis (LDA)** achieved the highest test mean balanced accuracy (0.8412), outperforming other algorithms.  \n",
    "Since LDA is not tree-based, we use **SHAP’s model-agnostic KernelExplainer** to compute feature contributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FW0SwPA6OXIf",
   "metadata": {
    "id": "FW0SwPA6OXIf"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ee2zcXH_D-cQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "2adc734b4fad46eeb4d6b62cc1acbde5",
      "89e86be0768341ebb325488c3fe94e62",
      "62fcf42b111e4548b9265cb71ce5e36d",
      "ade2568a78ba4b9c950b12e2228764de",
      "4bf0125bfd834800b74ce58386a62467",
      "24f0b841443d4a2f9a462af5e82464ee",
      "e3821534f9ab4b5a862f551cc59e5bc0",
      "a00d981289674999b81bfa73e1ab627e",
      "ec9e6d962ceb4e4391c433173b5adbdc",
      "6d1baff1f35245a690d17723becd6906",
      "6aa22a9f6ad849d98c54b595ac32a1cb"
     ]
    },
    "id": "Ee2zcXH_D-cQ",
    "outputId": "905d9aaa-b327-4592-ce00-0586a2a6310a"
   },
   "outputs": [],
   "source": [
    "# 1) LDA modelini eval_azm içinden al\n",
    "lda_keys = [k for k in getattr(eval_azm, \"store_models\", {}).keys() if k.startswith(\"LDA_\") or k.startswith(\"GS_LDA_\")]\n",
    "if not lda_keys:\n",
    "    raise RuntimeError(\"Azithromycin için LDA modeli bulunamadı; önce ilgili model hücrelerini çalıştırın.\")\n",
    "lda_key   = sorted(lda_keys)[0]\n",
    "lda_model = eval_azm.store_models[lda_key]\n",
    "\n",
    "# 2) Özellik matrisi (hedefi çıkar)\n",
    "X_all = eval_azm.X.drop(columns=[eval_azm.target_name], errors=\"ignore\")\n",
    "\n",
    "# 3) Arka plan (background) ve açıklanacak örneklem (hız için sınırlıyoruz)\n",
    "#    Not: k-means merkezleri genelde daha hızlıdır; istersen sample() da kullanabilirsin.\n",
    "X_bg     = shap.kmeans(X_all, 50)                # ~50 merkez (hız/kararlılık dengesi)\n",
    "X_sample = X_all.sample(min(len(X_all), 300), random_state=42)\n",
    "\n",
    "# 4) Model çıktısını KernelExplainer’a uygun fonksiyon olarak tanımla\n",
    "#    Tercihen predict_proba'nın pozitif sınıf (1) olasılığını döndürelim.\n",
    "def f_proba(data):\n",
    "    df = pd.DataFrame(data, columns=X_all.columns)\n",
    "    # Çoğu sklearn LDA'da predict_proba vardır; yoksa decision_function kullan.\n",
    "    if hasattr(lda_model, \"predict_proba\"):\n",
    "        return lda_model.predict_proba(df)[:, 1]\n",
    "    else:\n",
    "        # decision_function dönerse onu sigmoid'e map etmek seçenek olabilir,\n",
    "        # fakat çoğu LDA'da predict_proba mevcut.\n",
    "        return lda_model.decision_function(df)\n",
    "\n",
    "# 5) KernelExplainer ve SHAP değerleri\n",
    "explainer   = shap.KernelExplainer(f_proba, X_bg)\n",
    "shap_values = explainer.shap_values(X_sample, nsamples=100)   # nsamples↑ = daha doğru, ama yavaş\n",
    "\n",
    "# 6) Global açıklama – Beeswarm\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values, X_sample, show=False)\n",
    "plt.title(\"SHAP Summary – Azithromycin / LDA (KernelExplainer)\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "print(\"----------------------\")\n",
    "print(\"----------------------\")\n",
    "print(\"----------------------\")\n",
    "\n",
    "# 7) Global açıklama – Bar (mean |SHAP|)\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values, X_sample, plot_type=\"bar\", show=False)\n",
    "plt.title(\"Mean |SHAP| – Azithromycin / LDA (KernelExplainer)\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LDunzA79Pf2h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "LDunzA79Pf2h",
    "outputId": "2f130d29-142c-4841-ace2-635a2c099540"
   },
   "outputs": [],
   "source": [
    "# 8) Optional Top-10 features\n",
    "imp = np.abs(shap_values).mean(axis=0)\n",
    "top10_azm = pd.DataFrame({\"feature\": X_sample.columns, \"mean_abs_shap\": imp}) \\\n",
    "              .sort_values(\"mean_abs_shap\", ascending=False) \\\n",
    "              .head(10).reset_index(drop=True)\n",
    "display(top10_azm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bpu0iDG9U1o4",
   "metadata": {
    "id": "bpu0iDG9U1o4"
   },
   "source": [
    "## 7.9 Azithromycin Resistance – LIME Explainability (LDA Model)\n",
    "\n",
    "In this section, we explain the best-performing Azithromycin model (LDA) using LIME (local, model-agnostic). The code below selects the trained LDA from the evaluation pipeline, builds a tabular explainer on the feature matrix (target removed), chooses an instance to explain, and then produces (i) a local bar plot of weighted feature contributions and (ii) a readable top-k feature list with weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wdPoHK6nU984",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wdPoHK6nU984",
    "outputId": "c4b21ddc-f4fe-46e5-93e9-4a4014998d4b"
   },
   "outputs": [],
   "source": [
    "# 1) Pick the LDA model key (prefer GS_LDA_* over LDA_*)\n",
    "lda_keys = [k for k in getattr(eval_azm, \"store_models\", {}).keys() if k.startswith(\"GS_LDA_\")] \\\n",
    "           or [k for k in getattr(eval_azm, \"store_models\", {}).keys() if k.startswith(\"LDA_\")]\n",
    "if not lda_keys:\n",
    "    raise RuntimeError(\"No LDA model found for Azithromycin. Please run the LDA training cells first.\")\n",
    "lda_key   = sorted(lda_keys)[0]\n",
    "lda_model = eval_azm.store_models[lda_key]\n",
    "\n",
    "# 2) Build the feature matrix (drop target) and class names\n",
    "X_azm = eval_azm.X.drop(columns=[eval_azm.target_name], errors=\"ignore\").copy()\n",
    "y_azm = getattr(eval_azm, \"y\", None)\n",
    "class_names = [\"0\",\"1\"] if y_azm is None else [str(c) for c in sorted(pd.unique(y_azm))]\n",
    "\n",
    "# 3) Create a LIME tabular explainer using the training matrix\n",
    "explainer = LimeTabularExplainer(\n",
    "    training_data=X_azm.values,\n",
    "    feature_names=X_azm.columns.tolist(),\n",
    "    class_names=class_names,\n",
    "    mode=\"classification\",\n",
    "    discretize_continuous=True\n",
    ")\n",
    "\n",
    "# 4) Choose an instance to explain and define predict_fn\n",
    "instance_idx = 0          # change to 10, 25, ... as needed\n",
    "num_features = 10         # number of top contributing features to list\n",
    "num_samples  = 5000       # number of synthetic samples LIME will generate\n",
    "\n",
    "x0 = X_azm.iloc[instance_idx].values\n",
    "\n",
    "# LDA usually supports predict_proba; fallback to decision_function if needed\n",
    "def predict_fn(data):\n",
    "    df = pd.DataFrame(data, columns=X_azm.columns)\n",
    "    if hasattr(lda_model, \"predict_proba\"):\n",
    "        return lda_model.predict_proba(df)\n",
    "    else:\n",
    "        # If only decision_function exists, convert to a 2-column \"prob-like\" output\n",
    "        # (simple logistic mapping for demonstration; adjust if your API differs)\n",
    "        scores = lda_model.decision_function(df)\n",
    "        # Map scores to (p0, p1)\n",
    "        p1 = 1 / (1 + np.exp(-scores))\n",
    "        p0 = 1 - p1\n",
    "        return np.c_[p0, p1]\n",
    "\n",
    "# 5) Generate the explanation and visualize it\n",
    "exp = explainer.explain_instance(\n",
    "    data_row=x0,\n",
    "    predict_fn=predict_fn,\n",
    "    num_features=num_features,\n",
    "    num_samples=num_samples\n",
    ")\n",
    "\n",
    "fig = exp.as_pyplot_figure()\n",
    "_ = fig.suptitle(f\"LIME Explanation – Azithromycin / LDA – {lda_key} – idx={instance_idx}\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# 6) Human-readable list (feature rule, weight) + DataFrame\n",
    "pairs = exp.as_list()  # [(feature_rule, weight), ...]\n",
    "print(f\"\\nTop {num_features} features (LIME weights):\")\n",
    "for f, w in pairs:\n",
    "    print(f\"{f}  ==>  {w:+.4f}\")\n",
    "\n",
    "top_df = pd.DataFrame(pairs, columns=[\"feature_rule\", \"lime_weight\"])\n",
    "display(top_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ctVs0oAB2M-",
   "metadata": {
    "id": "8ctVs0oAB2M-"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "N4din7VgdbGu",
   "metadata": {
    "id": "N4din7VgdbGu"
   },
   "source": [
    "# 8.Cefixime Resistance Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GfiJ5d2WePHm",
   "metadata": {
    "id": "GfiJ5d2WePHm"
   },
   "source": [
    "## 8.1 Load and summarise cfx_sr dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jPQarf2vdfgo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jPQarf2vdfgo",
    "outputId": "ff2dd55c-8783-4158-fc18-7b3a651dff0c"
   },
   "outputs": [],
   "source": [
    "case_cfx = get_unitigs()\n",
    "case_cfx.get_case('cfx_sr')\n",
    "print(case_cfx.X[case_cfx.target_name].value_counts())\n",
    "print(\"Shape:\", case_cfx.X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pW1d1zM5eh2T",
   "metadata": {
    "id": "pW1d1zM5eh2T"
   },
   "source": [
    "## 8.2 Down-sample + SMOTENC balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0wrM9mv7ek2-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0wrM9mv7ek2-",
    "outputId": "49c8670d-6df1-43b2-aa10-b9c1b25fc728"
   },
   "outputs": [],
   "source": [
    "mod_cfx = mod_unitigs(case_cfx)\n",
    "mod_cfx.train  = mod_cfx.X.drop([mod_cfx.target_name], axis=1)\n",
    "mod_cfx.target = mod_cfx.X[mod_cfx.target_name].copy()\n",
    "mod_cfx.split_case(frac_id=0.1)         # keep 10 % of class 0\n",
    "mod_cfx.smote(smote_id='smotenc',\n",
    "              smote_strat=1.0,\n",
    "              k_neighbours=2)\n",
    "print(mod_cfx.X[mod_cfx.target_name].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wqPxjsb7eo_o",
   "metadata": {
    "id": "wqPxjsb7eo_o"
   },
   "source": [
    "## 8.3 Model roster & 4-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u-Ev_JNCeqA-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u-Ev_JNCeqA-",
    "outputId": "83a35fd5-b724-4158-a750-6daa41167171"
   },
   "outputs": [],
   "source": [
    "models_cfx = []\n",
    "models_cfx += [\n",
    "    ('LDA',  LinearDiscriminantAnalysis()),\n",
    "    ('KNN',  KNeighborsClassifier()),\n",
    "    ('NB',   GaussianNB()),\n",
    "    ('SVC',  SVC()),\n",
    "    ('TREE', DecisionTreeClassifier()),\n",
    "    ('GBM',  GradientBoostingClassifier(n_estimators=10)),\n",
    "    ('XGB',  XGBClassifier(n_estimators=10, verbosity=0)),\n",
    "    ('CAT',  CatBoostClassifier(silent=True, n_estimators=10)),\n",
    "    ('RF',   RandomForestClassifier(n_estimators=10))\n",
    "]\n",
    "eval_cfx = class_eval(data=mod_cfx, models=models_cfx, nfold=4)\n",
    "eval_cfx.cv(type_id='kfold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KvBaUcFSet91",
   "metadata": {
    "id": "KvBaUcFSet91"
   },
   "source": [
    "## 8.4 GBM GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oBFEW-N4evAG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oBFEW-N4evAG",
    "outputId": "09013131-fd94-492f-cad4-a3ed517922f3"
   },
   "outputs": [],
   "source": [
    "gbm_params = {'n_estimators':[50,100,150],\n",
    "              'learning_rate':[0.01,0.05,0.1],\n",
    "              'max_depth':[3,4,5]}\n",
    "gs_gbm = [('GBM', GradientBoostingClassifier(), gbm_params)]\n",
    "eval_cfx_gbm = class_eval(data=mod_cfx, models=gs_gbm, nfold=4,\n",
    "                          shuffle_id=True, random_state=42)\n",
    "eval_cfx_gbm.gscv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ywZxA3M9ezQd",
   "metadata": {
    "id": "ywZxA3M9ezQd"
   },
   "source": [
    "## 8.5 SVC GridSearch + coef analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D_DX2tv6e1ZK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D_DX2tv6e1ZK",
    "outputId": "5ceadef3-af8b-4640-b566-f502ad078e0e"
   },
   "outputs": [],
   "source": [
    "svc_params = {'C':[0.01,0.1,1,10],\n",
    "              'gamma':[1e-4,1e-5],\n",
    "              'kernel':['linear']}\n",
    "gs_svc_cfx = [('SVC', SVC(class_weight='balanced'), svc_params)]\n",
    "eval_cfx_svc = class_eval(data=mod_cfx, models=gs_svc_cfx, nfold=4,\n",
    "                          shuffle_id=True, random_state=42)\n",
    "eval_cfx_svc.gscv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AypV_U-cmAMV",
   "metadata": {
    "id": "AypV_U-cmAMV"
   },
   "source": [
    "## 8.6 Cefixime Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I8VZ8Mx9lYhg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 506
    },
    "id": "I8VZ8Mx9lYhg",
    "outputId": "7fee14ff-dc42-4630-d428-7690f05c2bec"
   },
   "outputs": [],
   "source": [
    "neg_seq_cfx, pos_seq_cfx = fi_svc(\n",
    "    eval_cfx_svc.store_models['GS_SVC_0'],\n",
    "    list(eval_cfx_svc.X.columns),\n",
    "    top_features=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SMh9aIqolZnO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SMh9aIqolZnO",
    "outputId": "132d2885-bcd1-4db9-f8d3-58184d3b8201"
   },
   "outputs": [],
   "source": [
    "neg_seq_cfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bCpkl-pUlaXP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bCpkl-pUlaXP",
    "outputId": "9374ef31-2d69-4100-8e2d-5c07d9ea5e36"
   },
   "outputs": [],
   "source": [
    "pos_seq_cfx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z6hnUTSwdc-Y",
   "metadata": {
    "id": "z6hnUTSwdc-Y"
   },
   "source": [
    "## 8.7 Cefixime Resistance – Model Evaluation Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k5r7Jxoldh0d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 915
    },
    "id": "k5r7Jxoldh0d",
    "outputId": "f4c11d56-1e72-437f-8342-4a3b0ab11665"
   },
   "outputs": [],
   "source": [
    "# 1. Skor sözlüklerini DataFrame’e çevir\n",
    "df_tr_cfx = pd.DataFrame(eval_cfx.dic_tr)\n",
    "df_te_cfx = pd.DataFrame(eval_cfx.dic_te)\n",
    "\n",
    "# 2. Ortalama skorları hesapla\n",
    "summary_cfx = pd.DataFrame({\n",
    "    \"Model\": df_te_cfx.columns,\n",
    "    \"Train Mean Balanced Accuracy\": df_tr_cfx.mean().values,\n",
    "    \"Test Mean Balanced Accuracy\": df_te_cfx.mean().values\n",
    "}).sort_values(\"Test Mean Balanced Accuracy\", ascending=False)\n",
    "\n",
    "# 3. Tabloyu göster\n",
    "display(summary_cfx)\n",
    "\n",
    "# 4. Grafikle görselleştir\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=summary_cfx, x=\"Test Mean Balanced Accuracy\", y=\"Model\", palette=\"Blues_d\")\n",
    "plt.title(\"Classifier Performance on Cefixime Resistance (Test Balanced Accuracy)\", fontsize=14)\n",
    "plt.xlabel(\"Mean Balanced Accuracy (Test)\")\n",
    "plt.ylabel(\"Model\")\n",
    "plt.xlim(0.5, 1.0)\n",
    "plt.grid(True, axis='x', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55IzdXalPLIl",
   "metadata": {
    "id": "55IzdXalPLIl"
   },
   "source": [
    "## 8.8 Cefixime SHAP Explainability (GBM Model)\n",
    "\n",
    "For the Cefixime resistance prediction task, the **Gradient Boosting Machine (GBM)** model achieved the highest test mean balanced accuracy (0.9508), outperforming other algorithms.  \n",
    "Since GBM is a tree-based model, we applied **SHAP’s TreeExplainer** for efficient and accurate feature attribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guAoAUeKPljy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 953
    },
    "id": "guAoAUeKPljy",
    "outputId": "368e7324-f3b3-4c97-a2b8-6f1bf9d28955"
   },
   "outputs": [],
   "source": [
    "# 1) GBM model anahtarını seç (öncelik: GS_GBM_* > GBM_*)\n",
    "gbm_keys = [k for k in getattr(eval_cfx, \"store_models\", {}).keys() if k.startswith(\"GS_GBM_\")] \\\n",
    "           or [k for k in getattr(eval_cfx, \"store_models\", {}).keys() if k.startswith(\"GBM_\")]\n",
    "if not gbm_keys:\n",
    "    raise RuntimeError(\"Cefixime için GBM modeli bulunamadı. Lütfen GBM eğitim hücrelerini çalıştırın.\")\n",
    "\n",
    "gbm_key   = sorted(gbm_keys)[0]\n",
    "gbm_model = eval_cfx.store_models[gbm_key]\n",
    "\n",
    "# 2) Özellik matrisi (hedef sütunu çıkar)\n",
    "X_cfx = eval_cfx.X.drop(columns=[eval_cfx.target_name], errors=\"ignore\")\n",
    "\n",
    "# 3) SHAP TreeExplainer ve değerler\n",
    "explainer = shap.TreeExplainer(gbm_model)\n",
    "shap_values = explainer.shap_values(X_cfx)\n",
    "\n",
    "# 4) Global açıklama – Beeswarm\n",
    "plt.figure(figsize=(10, 6))\n",
    "try:\n",
    "    shap.summary_plot(shap_values[1], X_cfx, show=False)  # ikili sınıfta pozitif sınıf\n",
    "except Exception:\n",
    "    shap.summary_plot(shap_values, X_cfx, show=False)\n",
    "plt.title(\"SHAP Summary – Cefixime / GBM\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "print(\"----------------------\")\n",
    "print(\"----------------------\")\n",
    "print(\"----------------------\")\n",
    "\n",
    "# 5) Global açıklama – Bar (mean |SHAP|)\n",
    "plt.figure(figsize=(10, 6))\n",
    "try:\n",
    "    shap.summary_plot(shap_values[1], X_cfx, plot_type=\"bar\", show=False)\n",
    "except Exception:\n",
    "    shap.summary_plot(shap_values, X_cfx, plot_type=\"bar\", show=False)\n",
    "plt.title(\"Mean |SHAP| – Cefixime / GBM\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ShjaYQkTcO4D",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "ShjaYQkTcO4D",
    "outputId": "19bdd2a5-dc62-4d7d-91c2-801ef8408322"
   },
   "outputs": [],
   "source": [
    "sv   = shap_values[1] if isinstance(shap_values, list) else shap_values\n",
    "imp  = np.abs(sv).mean(axis=0)\n",
    "top10_cfx = pd.DataFrame({\"feature\": X_cfx.columns, \"mean_abs_shap\": imp}) \\\n",
    "                  .sort_values(\"mean_abs_shap\", ascending=False) \\\n",
    "                  .head(10).reset_index(drop=True)\n",
    "display(top10_cfx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kuk7cHE3Wys0",
   "metadata": {
    "id": "Kuk7cHE3Wys0"
   },
   "source": [
    "## 8.9 Cefixime Resistance – LIME Explainability (CAT MOdel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WOn4rq66W8Sa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 992
    },
    "id": "WOn4rq66W8Sa",
    "outputId": "b0054c4f-746d-4335-cf40-9657d7cdde18"
   },
   "outputs": [],
   "source": [
    "gbm_keys = [k for k in getattr(eval_cfx, \"store_models\", {}).keys() if k.startswith(\"GS_GBM_\")] \\\n",
    "           or [k for k in getattr(eval_cfx, \"store_models\", {}).keys() if k.startswith(\"GBM_\")]\n",
    "if not gbm_keys:\n",
    "    raise RuntimeError(\"No GBM model found for Cefixime.\")\n",
    "gbm_key   = sorted(gbm_keys)[0]\n",
    "gbm_model = eval_cfx.store_models[gbm_key]\n",
    "\n",
    "X_cfx = eval_cfx.X.drop(columns=[eval_cfx.target_name], errors=\"ignore\").copy()\n",
    "y_cfx = getattr(eval_cfx, \"y\", None)\n",
    "class_names = [\"0\",\"1\"] if y_cfx is None else [str(c) for c in sorted(pd.unique(y_cfx))]\n",
    "\n",
    "explainer = LimeTabularExplainer(\n",
    "    training_data=X_cfx.values,\n",
    "    feature_names=X_cfx.columns.tolist(),\n",
    "    class_names=class_names,\n",
    "    mode=\"classification\",\n",
    "    discretize_continuous=True\n",
    ")\n",
    "\n",
    "instance_idx = 0\n",
    "x0 = X_cfx.iloc[instance_idx].values\n",
    "predict_fn = lambda data: gbm_model.predict_proba(pd.DataFrame(data, columns=X_cfx.columns))\n",
    "\n",
    "exp = explainer.explain_instance(x0, predict_fn, num_features=10, num_samples=5000)\n",
    "fig = exp.as_pyplot_figure(); _ = fig.suptitle(f\"LIME – Cefixime / GBM – {gbm_key} – idx={instance_idx}\", y=1.02); plt.show()\n",
    "\n",
    "pairs = exp.as_list()\n",
    "print(\"\\nTop 10 features (LIME weights):\")\n",
    "for f, w in pairs: print(f\"{f}  ==>  {w:+.4f}\")\n",
    "display(pd.DataFrame(pairs, columns=[\"feature_rule\",\"lime_weight\"]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
